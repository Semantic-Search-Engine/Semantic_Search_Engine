{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "import torch\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import time\n",
        "import datetime"
      ],
      "metadata": {
        "id": "ztHmKeA_sfug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwHXK48xOrT9",
        "outputId": "814e512d-242f-4e1d-c02d-e343ea304241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy==1.21.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrQI53y6tT7l",
        "outputId": "54608dcd-3336-403a-bd89-f4ec1c8ca19d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 22.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 50.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed Nov 30 12:25:33 2022\n",
        "\n",
        "@author: MD RAFI\n",
        "\"\"\"\n",
        "class LocalitySensitiveHashing:\n",
        "    \n",
        "    def __init__(self,n_planes,plane_dimensions,n_iterations):\n",
        "        \n",
        "        self.n=n_planes\n",
        "        self.d=plane_dimensions\n",
        "        self.n_iterations=n_iterations\n",
        "        self.dic=[]\n",
        "        self.planes=[]\n",
        "    def Random_planes(self,n,d):\n",
        "        \n",
        "        return np.random.normal(size=(n,d))\n",
        "    \n",
        "    \n",
        "    def fit(self,data):\n",
        "        \n",
        "        y_train=data[:,1:]\n",
        "        #no of iterations\n",
        "        for i in tqdm(range(self.n_iterations)):\n",
        "            #generating Random planes\n",
        "            random=self.Random_planes(self.n, self.d)\n",
        "            #dot product\n",
        "            a=np.dot(y_train,random.T)\n",
        "            #bins\n",
        "            h=np.where(a>1,1,0)\n",
        "            #append random planes\n",
        "            self.planes.append(random)\n",
        "            #inserting bins into dictionary\n",
        "            new_dic=defaultdict(list)\n",
        "            for i in range(len(h)):\n",
        "              new_dic[str(h[i])].append(data[i,0])\n",
        "            self.dic.append(new_dic)\n",
        "    \n",
        "    def add_point(self,points,index):\n",
        "       for i in range(len(points)):\n",
        "           for j in range(len(self.planes)):\n",
        "                dot=np.dot(points[i],self.planes[j].T)\n",
        "                dot=np.where(dot>1,1,0)\n",
        "                self.dic[j][str(dot)].append(index[i,0])\n",
        "   \n",
        "    \n",
        "    def fetch(self,point):\n",
        "        buckets=set()\n",
        "        for i in range(len(self.planes)):\n",
        "          dot=np.dot(point,self.planes[i].T)\n",
        "          dot=np.where(dot>1,1,0)\n",
        "          buckets.update(self.dic[i][str(dot)])\n",
        "          #print(buckets)\n",
        "        return buckets\n",
        "\n",
        "\n",
        "    def ShowData(self,vectors,query_vec):\n",
        "        x=cosine_similarity(vectors[:,1:],query_vec)\n",
        "        stack=np.array(sorted(np.hstack((vectors[:,0].reshape(-1,1),x.reshape(-1,1))),key=lambda x : x[-1],reverse=True))\n",
        "        return stack[:,0]\n",
        "\n",
        "\n",
        "#load tokenizer and model\n",
        "with open('/content/drive/MyDrive/pickle files/tokenizer.pkl', 'rb') as file:\n",
        "  tokenizer=pickle.load(file)\n",
        "with open('/content/drive/MyDrive/pickle files/model.pkl', 'rb') as file:\n",
        "  bert=pickle.load(file)\n",
        "\n",
        "## Load data_title Lsh and data_abstract Lsh\n",
        "\n",
        "with open('/content/drive/MyDrive/pickle files/LSH_title.pkl', 'rb') as file:\n",
        "  Lsh_data_title=pickle.load(file)\n",
        "\n",
        "def convert_to_embedding(in_text, MAX_LEN = 150):\n",
        "\n",
        "    phrase = re.sub(r\"http\\S+\", \"\", in_text)\n",
        "    phrase = re.sub(r\"won't\", \"will not\",phrase )\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "    phrase = re.sub('[^A-Za-z0-9]+', ' ', phrase)\n",
        "\n",
        "\n",
        "    input_ids = tokenizer.encode(\n",
        "                        phrase, \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = MAX_LEN,                           \n",
        "                   )    \n",
        "    \n",
        "    #print(\"input ids\",input_ids)\n",
        "\n",
        "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\", \n",
        "                              truncating=\"post\", padding=\"post\")\n",
        "    #print(\"results\",results)\n",
        "    \n",
        "    # Remove the outer list.\n",
        "    input_ids = results[0]\n",
        "    #print(\"input ids\",input_ids)\n",
        "\n",
        "    # Create attention masks    \n",
        "    attention_mask = [int(i>0) for i in input_ids]\n",
        "    #print(\"attention_mask\",attention_mask)\n",
        "    \n",
        "    # Convert to tensors.\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "    #print(\"input ids\",input_ids)\n",
        "    #print(\"attention_mask\",attention_mask)\n",
        "\n",
        "    # Add an extra dimension for the \"batch\" (even though there is only one \n",
        "    # input in this batch.)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "\n",
        "    #print(\"input ids\",input_ids)\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    bert.eval()\n",
        "\n",
        "    #input_ids = input_ids.to(device)\n",
        "    #attention_mask = attention_mask.to(device)\n",
        "    \n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers. \n",
        "    with torch.no_grad():        \n",
        "        o  = bert(\n",
        "                        input_ids = input_ids, \n",
        "                        token_type_ids = None, \n",
        "                        attention_mask = attention_mask)\n",
        "        \n",
        "        h_s = o[1][1:]\n",
        "\n",
        "    layer_i = 11 # The last BERT layer before the classifier.\n",
        "    batch_i = 0 # Only one input in the batch.\n",
        "    token_i = 0 # The first token, corresponding to [CLS]\n",
        "\n",
        "    #print(h_s[11].shape)\n",
        "    # Extract the embedding.\n",
        "    embedding = h_s[layer_i][batch_i][token_i]\n",
        "\n",
        "    # Move to the CPU and convert to numpy ndarray.\n",
        "    embedding = embedding.detach().cpu().numpy()\n",
        "\n",
        "    return(embedding)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/pickle files/Final_dataset1.pkl', 'rb') as file:\n",
        "  dataset=pickle.load(file)\n",
        "\n",
        " \n",
        "data_title_embeddings = pd.read_csv(\"/content/drive/MyDrive/pickle files/final_embeddings\")\n",
        "data_title_embeddings = data_title_embeddings.drop(\"Unnamed: 0\" , axis=1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Jdj9dFBnsB4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t0 = time.time()\n",
        "query=\"Principal component analysis\"\n",
        "query_embedding=convert_to_embedding(query)\n",
        "indices_data_title=list(map(int,Lsh_data_title.fetch(query_embedding)))\n",
        "\n",
        "sorted_title_indices=Lsh_data_title.ShowData(data_title_embeddings.iloc[indices_data_title].to_numpy(),np.array([query_embedding]))\n",
        "output = dataset.iloc[sorted_title_indices]\n",
        "print(\"Time taken :\",format_time(time.time() - t0))\n",
        "out_json = output.to_json(orient='split') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1ON-5kOs0qH",
        "outputId": "0570dac9-db91-411f-efc7-400a9c92b457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken : 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "zOmty3CkTpib",
        "outputId": "59bf7625-cea3-4305-e5c6-b6cc9fe2c5bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"columns\":[\"year\",\"title\",\"abstract\",\"auhtors\"],\"index\":[16372,17462,3172,4641,1597,2939,14608,2167,4937,1581,4087,22403,23599,20779,12902,17448,2740,2260,911,27334,15783,18701,22809,11943,19999,19686,3094,24441,28095,1086,5715,2572,5927,20276,18537,14631,7574,18845,22094,21279,16252,10129,28852,19250,14301,5273,1478,4435,20269,25058,15750,868,17958,9421,2724,12744,26978,20217,21992,23219,29082,1265,10593,13391,1673,17354,26835,17879,28347,26812,20682],\"data\":[[2017,\"Contrastive Principal Component Analysis\",\"We present a new technique called contrastive principal component analysis\\\\n(cPCA) that is designed to discover low-dimensional structure that is unique to\\\\na dataset, or enriched in one dataset relative to other data. The technique is\\\\na generalization of standard PCA, for the setting where multiple datasets are\\\\navailable -- e.g. a treatment and a control group, or a mixed versus a\\\\nhomogeneous population -- and the goal is to explore patterns that are specific\\\\nto one of the datasets. We conduct a wide variety of experiments in which cPCA\\\\nidentifies important dataset-specific patterns that are missed by PCA,\\\\ndemonstrating that it is useful for many applications: subgroup discovery,\\\\nvisualizing trends, feature selection, denoising, and data-dependent\\\\nstandardization. We provide geometrical interpretations of cPCA and show that\\\\nit satisfies desirable theoretical guarantees. We also extend cPCA to nonlinear\\\\nsettings in the form of kernel cPCA. We have released our code as a python\\\\npackage and documentation is on Github.\",\" Abubakar Abid,  Martin J. Zhang,  Vivek K. Bagaria,  James Zou\"],[2012,\"Generalized Principal Component Analysis (GPCA)\",\"This paper presents an algebro-geometric solution to the problem of\\\\nsegmenting an unknown number of subspaces of unknown and varying dimensions\\\\nfrom sample data points. We represent the subspaces with a set of homogeneous\\\\npolynomials whose degree is the number of subspaces and whose derivatives at a\\\\ndata point give normal vectors to the subspace passing through the point. When\\\\nthe number of subspaces is known, we show that these polynomials can be\\\\nestimated linearly from data; hence, subspace segmentation is reduced to\\\\nclassifying one point per subspace. We select these points optimally from the\\\\ndata set by minimizing certain distance function, thus dealing automatically\\\\nwith moderate noise in the data. A basis for the complement of each subspace is\\\\nthen recovered by applying standard PCA to the collection of derivatives\\\\n(normal vectors). Extensions of GPCA that deal with data in a high- dimensional\\\\nspace and with an unknown number of subspaces are also presented. Our\\\\nexperiments on low-dimensional data show that GPCA outperforms existing\\\\nalgebraic algorithms based on polynomial factorization and provides a good\\\\ninitialization to iterative techniques such as K-subspaces and Expectation\\\\nMaximization. We also present applications of GPCA to computer vision problems\\\\nsuch as face clustering, temporal video segmentation, and 3D motion\\\\nsegmentation from point correspondences in multiple affine views.\",\" Rene Vidal,  Yi Ma,  Shankar Sastry\"],[2008,\"Robust Kernel Principal Component Analysis\",\"Kernel Principal Component Analysis (KPCA) is a popular generalization of linear PCA that allows non-linear feature extraction. In KPCA, data in the input space is mapped to higher (usually) dimensional feature space where the data can be linearly modeled. The feature space is typically induced implicitly by a kernel function, and linear PCA in the feature space is performed via the kernel trick. However, due to the implicitness of the feature space, some extensions of PCA such as robust PCA cannot be directly generalized to KPCA. This paper presents a technique to overcome this problem, and extends it to a unified framework for treating noise, missing data, and outliers in KPCA. Our method is based on a novel cost function to perform inference in KPCA. Extensive experiments, in both synthetic and real data, show that our algorithm outperforms existing methods.\",null],[2013,\"Similarity Component Analysis\",\"Measuring similarity is crucial to many learning tasks. It is also a richer and broader notion than what most metric learning algorithms can model. For example, similarity can arise from the process of aggregating the decisions of multiple latent components, where each latent component compares data in its own way by focusing on a different subset of features. In this paper, we propose Similarity Component Analysis (SCA), a probabilistic graphical model that discovers those latent components from data. In SCA, a latent component generates a local similarity value, computed with its own metric, independently of other components. The final similarity measure is then obtained by combining the local similarity values with a (noisy-)OR gate. We derive an EM-based algorithm for fitting the model parameters with similarity-annotated data from pairwise comparisons. We validate the SCA model on synthetic datasets where SCA discovers the ground-truth about the latent components. We also apply SCA to a multiway classification task and a link prediction task. For both tasks, SCA attains significantly better prediction accuracies than competing methods. Moreover, we show how SCA can be instrumental in exploratory analysis of data, where we gain insights about the data by examining patterns hidden in its latent components\\' local similarity values.\",null],[2000,\"Sparse Kernel Principal Component Analysis\",\"\\'Kernel\\'  principal  component  analysis  (PCA)  is  an  elegant  non(cid:173)linear  generalisation  of the  popular  linear  data  analysis  method, where  a  kernel function  implicitly  defines  a  nonlinear transforma(cid:173)tion into a feature space wherein standard PCA is  performed.  Un(cid:173)fortunately,  the  technique  is  not  \\'sparse\\',  since  the  components thus obtained are expressed in terms of kernels associated with ev(cid:173)ery training vector.  This paper shows  that by  approximating the covariance matrix in  feature  space by a  reduced  number of exam(cid:173)ple vectors, using a  maximum-likelihood approach, we may obtain a highly sparse form  of kernel PCA without loss of effectiveness. 1 \",\"Charles Isbell , Paul Viola\"],[2012,\"Semiparametric Principal Component Analysis\",\"We propose two new principal component analysis methods in this paper utilizinga semiparametric model. The according methods are named Copula ComponentAnalysis (COCA) and Copula PCA. The semiparametric model assumes that, af-ter unspeci\\\\ufb01ed marginally monotone transformations, the distributions are multi-variate Gaussian. The COCA and Copula PCA accordingly estimate the leadingeigenvectors of the correlation and covariance matrices of the latent Gaussian dis-tribution. The robust nonparametric rank-based correlation coef\\\\ufb01cient estimator,Spearman\\\\u2019s rho, is exploited in estimation. We prove that, under suitable condi-tions, although the marginal distributions can be arbitrarily continuous, the COCAand Copula PCA estimators obtain fast estimation rates and are feature selectionconsistent in the setting where the dimension is nearly exponentially large relativeto the sample size. Careful numerical experiments on the synthetic and real dataare conducted to back up the theoretical results. We also discuss the relationshipwith the transelliptical component analysis proposed by Han and Liu (2012).j=1 \\\\u03c9jujuTthe sample covariance S. By spectral decomposition, \\\\u03a3 = Pd1 \",\"Jarmo Hurri , David Eriksson , Michael Pearce , Jacob Gardner , Ryan Turner , Matthias Poloczek\"],[2012,\"Tree-dependent Component Analysis\",\"We present a generalization of independent component analysis (ICA), where\\\\ninstead of looking for a linear transform that makes the data components\\\\nindependent, we look for a transform that makes the data components well fit by\\\\na tree-structured graphical model. Treating the problem as a semiparametric\\\\nstatistical problem, we show that the optimal transform is found by minimizing\\\\na contrast function based on mutual information, a function that directly\\\\nextends the contrast function used for classical ICA. We provide two\\\\napproximations of this contrast function, one using kernel density estimation,\\\\nand another using kernel generalized variance. This tree-dependent component\\\\nanalysis framework leads naturally to an efficient general multivariate density\\\\nestimation technique where only bivariate density estimation needs to be\\\\nperformed.\",\" Francis R. Bach,  Michael I. Jordan\"],[2003,\"Extreme Components Analysis\",\"Principal components analysis (PCA) is one of the most widely usedtechniques in machine learning and data mining. Minor componentsanalysis (MCA) is less well known, but can also play an important rolein the presence of constraints on the data distribution. In this paper wepresent a probabilistic model for \\\\u201cextreme components analysis\\\\u201d (XCA)which at the maximum likelihood solution extracts an optimal combina-tion of principal and minor components. For a given number of compo-nents, the log-likelihood of the XCA model is guaranteed to be larger orequal than that of the probabilistic models for PCA and MCA. We de-scribe an ef\\\\ufb01cient algorithm to solve for the globally optimal solution.For log-convex spectra we prove that the solution consists of principalcomponents only, while for log-concave spectra the solution consists ofminor components. In general, the solution admits a combination of both.In experiments we explore the properties of XCA on some synthetic andreal-world datasets.1 \",\"Yan Karklin , Michael Lewicki , Ching-An Cheng , Byron Boots , Kyungjae Lee , Sungjoon Choi , Songhwai Oh\"],[2014,\"Improved Distributed Principal Component Analysis\",\"We study the distributed computing setting in which there are multiple servers, each holding a set of points, who wish to compute functions on the union of their point sets. A key task in this setting is Principal Component Analysis (PCA), in which the servers would like to compute a low dimensional subspace capturing as much of the variance of the union of their point sets as possible. Given a procedure for approximate PCA, one can use it to approximately solve problems such as $k$-means clustering and low rank approximation. The essential properties of an approximate distributed PCA algorithm are its communication cost and computational efficiency for a given desired accuracy in downstream applications. We give new algorithms and analyses for distributed PCA which lead to improved communication and computational costs for $k$-means clustering and related problems. Our empirical study on real world data shows a speedup of orders of magnitude, preserving communication with only a negligible degradation in solution quality. Some of these techniques we develop, such as input-sparsity subspace embeddings with high correctness probability with a dimension and sparsity independent of the error probability, may be of independent interest.\",null],[2000,\"Constrained Independent Component Analysis\",\"The  paper  presents  a  novel  technique  of constrained  independent component analysis  (CICA)  to introduce constraints into the clas(cid:173)sical ICA and solve the constrained optimization problem by using Lagrange  multiplier  methods.  This  paper  shows  that  CICA  can be used to order the resulted independent components in a specific manner and normalize the demixing matrix in the signal separation procedure.  It can systematically eliminate the ICA\\'s indeterminacy on permutation and dilation.  The experiments demonstrate the use of CICA  in  ordering of  independent  components  while  providing normalized demixing processes. Keywords:  Independent  component  analysis, constrained indepen(cid:173)dent component analysis, constrained optimization, Lagrange mul(cid:173)tiplier methods 1 \",\"Daphna Weinshall , David Jacobs , Yoram Gdalyahu , Wen-Hao Zhang , He Wang , K. Y. Michael Wong , Si Wu\"],[2011,\"Demixed Principal Component Analysis\",\"In many experiments, the data points collected live in high-dimensional observation spaces, yet can be assigned a set of labels or parameters. In electrophysiological recordings, for instance, the responses of populations of neurons generally depend on mixtures of experimentally controlled parameters. The heterogeneity and diversity of these parameter dependencies can make visualization and interpretation of such data extremely difficult. Standard dimensionality reduction techniques such as principal component analysis (PCA) can provide a succinct and complete description of the data, but the description is constructed independent of the relevant task variables and is often hard to interpret. Here, we start with the assumption that a particularly informative description is one that reveals the dependency of the high-dimensional data on the individual parameters. We show how to modify the loss function of PCA so that the principal components seek to capture both the maximum amount of variance about the data, while also depending on a minimum number of parameters. We call this method demixed principal component analysis (dPCA) as the principal components here segregate the parameter dependencies. We phrase the problem as a probabilistic graphical model, and present a fast Expectation-Maximization (EM) algorithm. We demonstrate the use of this algorithm for electrophysiological data and show that it serves to demix the parameter-dependence of a neural population response.\",null],[2015,\"Heavy-tailed Independent Component Analysis\",\"Independent component analysis (ICA) is the problem of efficiently recovering\\\\na matrix $A \\\\\\\\in \\\\\\\\mathbb{R}^{n\\\\\\\\times n}$ from i.i.d. observations of $X=AS$\\\\nwhere $S \\\\\\\\in \\\\\\\\mathbb{R}^n$ is a random vector with mutually independent\\\\ncoordinates. This problem has been intensively studied, but all existing\\\\nefficient algorithms with provable guarantees require that the coordinates\\\\n$S_i$ have finite fourth moments. We consider the heavy-tailed ICA problem\\\\nwhere we do not make this assumption, about the second moment. This problem\\\\nalso has received considerable attention in the applied literature. In the\\\\npresent work, we first give a provably efficient algorithm that works under the\\\\nassumption that for constant $\\\\\\\\gamma > 0$, each $S_i$ has finite\\\\n$(1+\\\\\\\\gamma)$-moment, thus substantially weakening the moment requirement\\\\ncondition for the ICA problem to be solvable. We then give an algorithm that\\\\nworks under the assumption that matrix $A$ has orthogonal columns but requires\\\\nno moment assumptions. Our techniques draw ideas from convex geometry and\\\\nexploit standard properties of the multivariate spherical Gaussian distribution\\\\nin a novel way.\",\" Joseph Anderson,  Navin Goyal,  Anupama Nandi,  Luis Rademacher\"],[2016,\"Randomized Independent Component Analysis\",\"Independent component analysis (ICA) is a method for recovering statistically\\\\nindependent signals from observations of unknown linear combinations of the\\\\nsources. Some of the most accurate ICA decomposition methods require searching\\\\nfor the inverse transformation which minimizes different approximations of the\\\\nMutual Information, a measure of statistical independence of random vectors.\\\\nTwo such approximations are the Kernel Generalized Variance or the Kernel\\\\nCanonical Correlation which has been shown to reach the highest performance of\\\\nICA methods. However, the computational effort necessary just for computing\\\\nthese measures is cubic in the sample size. Hence, optimizing them becomes even\\\\nmore computationally demanding, in terms of both space and time. Here, we\\\\npropose a couple of alternative novel measures based on randomized features of\\\\nthe samples - the Randomized Generalized Variance and the Randomized Canonical\\\\nCorrelation. The computational complexity of calculating the proposed\\\\nalternatives is linear in the sample size and provide a controllable\\\\napproximation of their Kernel-based non-random versions. We also show that\\\\noptimization of the proposed statistical properties yields a comparable\\\\nseparation error at an order of magnitude faster compared to Kernel-based\\\\nmeasures.\",\" Matan Sela,  Ron Kimmel\"],[2016,\"Principal Component Projection Without Principal Component Analysis\",\"We show how to efficiently project a vector onto the top principal components\\\\nof a matrix, without explicitly computing these components. Specifically, we\\\\nintroduce an iterative algorithm that provably computes the projection using\\\\nfew calls to any black-box routine for ridge regression.\\\\n  By avoiding explicit principal component analysis (PCA), our algorithm is the\\\\nfirst with no runtime dependence on the number of top principal components. We\\\\nshow that it can be used to give a fast iterative method for the popular\\\\nprincipal component regression problem, giving the first major runtime\\\\nimprovement over the naive method of combining PCA with regression.\\\\n  To achieve our results, we first observe that ridge regression can be used to\\\\nobtain a \\\\\"smooth projection\\\\\" onto the top principal components. We then sharpen\\\\nthis approximation to true projection using a low-degree polynomial\\\\napproximation to the matrix step function. Step function approximation is a\\\\ntopic of long-term interest in scientific computing. We extend prior theory by\\\\nconstructing polynomials with simple iterative structure and rigorously\\\\nanalyzing their behavior under limited precision.\",\" Roy Frostig,  Cameron Musco,  Christopher Musco,  Aaron Sidford\"],[2018,\"Robust Kronecker Component Analysis\",\"Dictionary learning and component analysis models are fundamental in learning\\\\ncompact representations that are relevant to a given task (feature extraction,\\\\ndimensionality reduction, denoising, etc.). The model complexity is encoded by\\\\nmeans of specific structure, such as sparsity, low-rankness, or nonnegativity.\\\\nUnfortunately, approaches like K-SVD - that learn dictionaries for sparse\\\\ncoding via Singular Value Decomposition (SVD) - are hard to scale to\\\\nhigh-volume and high-dimensional visual data, and fragile in the presence of\\\\noutliers. Conversely, robust component analysis methods such as the Robust\\\\nPrinciple Component Analysis (RPCA) are able to recover low-complexity (e.g.,\\\\nlow-rank) representations from data corrupted with noise of unknown magnitude\\\\nand support, but do not provide a dictionary that respects the structure of the\\\\ndata (e.g., images), and also involve expensive computations. In this paper, we\\\\npropose a novel Kronecker-decomposable component analysis model, coined as\\\\nRobust Kronecker Component Analysis (RKCA), that combines ideas from sparse\\\\ndictionary learning and robust component analysis. RKCA has several appealing\\\\nproperties, including robustness to gross corruption; it can be used for\\\\nlow-rank modeling, and leverages separability to solve significantly smaller\\\\nproblems. We design an efficient learning algorithm by drawing links with a\\\\nrestricted form of tensor factorization, and analyze its optimality and\\\\nlow-rankness properties. The effectiveness of the proposed approach is\\\\ndemonstrated on real-world applications, namely background subtraction and\\\\nimage denoising and completion, by performing a thorough comparison with the\\\\ncurrent state of the art.\",\" Mehdi Bahri,  Yannis Panagakis,  Stefanos Zafeiriou\"],[2016,\"Bayesian Neighbourhood Component Analysis\",\"Learning a good distance metric in feature space potentially improves the\\\\nperformance of the KNN classifier and is useful in many real-world\\\\napplications. Many metric learning algorithms are however based on the point\\\\nestimation of a quadratic optimization problem, which is time-consuming,\\\\nsusceptible to overfitting, and lack a natural mechanism to reason with\\\\nparameter uncertainty, an important property useful especially when the\\\\ntraining set is small and\\\\/or noisy. To deal with these issues, we present a\\\\nnovel Bayesian metric learning method, called Bayesian NCA, based on the\\\\nwell-known Neighbourhood Component Analysis method, in which the metric\\\\nposterior is characterized by the local label consistency constraints of\\\\nobservations, encoded with a similarity graph instead of independent pairwise\\\\nconstraints. For efficient Bayesian optimization, we explore the variational\\\\nlower bound over the log-likelihood of the original NCA objective. Experiments\\\\non several publicly available datasets demonstrate that the proposed method is\\\\nable to learn robust metric measures from small size dataset and\\\\/or from\\\\nchallenging training set with labels contaminated by errors. The proposed\\\\nmethod is also shown to outperform a previous pairwise constrained Bayesian\\\\nmetric learning method.\",\" Dong Wang,  Xiaoyang Tan\"],[2006,\"Large Margin Component Analysis\",\"Metric learning has been shown to signi\\\\ufb01cantly improve the accuracy of k-nearestneighbor (kNN) classi\\\\ufb01cation. In problems involving thousands of features, dis-tance learning algorithms cannot be used due to over\\\\ufb01tting and high computa-tional complexity. In such cases, previous work has relied on a two-step solution:\\\\ufb01rst apply dimensionality reduction methods to the data, and then learn a met-ric in the resulting low-dimensional subspace. In this paper we show that betterclassi\\\\ufb01cation performance can be achieved by unifying the objectives of dimen-sionality reduction and metric learning. We propose a method that solves forthe low-dimensional projection of the inputs, which minimizes a metric objectiveaimed at separating points in different classes by a large margin. This projectionis de\\\\ufb01ned by a signi\\\\ufb01cantly smaller number of parameters than metrics learnedin input space, and thus our optimization reduces the risks of over\\\\ufb01tting. Theoryand results are presented for both a linear as well as a kernelized version of thealgorithm. Overall, we achieve classi\\\\ufb01cation rates similar, and in several casessuperior, to those of support vector machines.1 \",\"Yves Grandvalet , Yoshua Bengio , Vikash Goel , Jameson Weng , Pascal Poupart\"],[2004,\"Neighbourhood Components Analysis\",\"             In this paper we propose a novel method for learning a Mahalanobis             distance measure to be used in the KNN classification algorithm. The             algorithm directly maximizes a stochastic variant of the leave-one-out             KNN score on the training set. It can also learn a low-dimensional lin-             ear embedding of labeled data that can be used for data visualization             and fast classification. Unlike other methods, our classification model             is non-parametric, making no assumptions about the shape of the class             distributions or the boundaries between them. The performance of the             method is demonstrated on several data sets, both for metric learning and             linear dimensionality reduction.1    \",\"Kwokleung Chan , Te-Won Lee , Terrence Sejnowski , Yuchen Pu , Weiyao Wang , Ricardo Henao , Liqun Chen , Zhe Gan , Chunyuan Li , Lawrence Carin , Maxim Kuznetsov , Daniil Polykovskiy , Dmitry Vetrov , Alex Zhebrak\"],[1995,\"Symplectic Nonlinear Component Analysis\",\"Statistically independent features  can be extracted by finding a fac(cid:173)torial representation of a signal distribution.  Principal Component Analysis  (PCA)  accomplishes  this  for  linear  correlated  and  Gaus(cid:173)sian  distributed signals.  Independent  Component Analysis  (ICA), formalized  by  Comon (1994),  extracts  features  in  the  case  of lin(cid:173)ear  statistical  dependent  but  not  necessarily  Gaussian  distributed signals.  Nonlinear  Component Analysis finally should find  a  facto(cid:173)rial  representation  for  nonlinear  statistical  dependent  distributed signals.  This  paper  proposes  for  this  task  a  novel  feed-forward, information  conserving,  nonlinear  map  - the  explicit  symplectic transformations.  It also solves the problem of non-Gaussian output distributions  by  considering  single  coordinate  higher  order  statis(cid:173)tics. 1 \",\"D. Lippe , Joshua Alspector , Uwe Dick , Peter Haider , Thomas Vanck , Michael Br\\\\u00fcckner , Tobias Scheffer\"],[2001,\"Rational Competitive Analysis\",\"Much work in computer science has adopted competitive analysis as a tool for\\\\ndecision making under uncertainty. In this work we extend competitive analysis\\\\nto the context of multi-agent systems. Unlike classical competitive analysis\\\\nwhere the behavior of an agent\\'s environment is taken to be arbitrary, we\\\\nconsider the case where an agent\\'s environment consists of other agents. These\\\\nagents will usually obey some (minimal) rationality constraints. This leads to\\\\nthe definition of rational competitive analysis. We introduce the concept of\\\\nrational competitive analysis, and initiate the study of competitive analysis\\\\nfor multi-agent systems. We also discuss the application of rational\\\\ncompetitive analysis to the context of bidding games, as well as to the\\\\nclassical one-way trading problem.\",\" Moshe Tennenholtz\"],[2017,\"Stochastic Canonical Correlation Analysis\",\"We tightly analyze the sample complexity of CCA, provide a learning algorithm\\\\nthat achieves optimal statistical performance in time linear in the required\\\\nnumber of samples (up to log factors), as well as a streaming algorithm with\\\\nsimilar guarantees.\",\" Chao Gao,  Dan Garber,  Nathan Srebro,  Jialei Wang,  Weiran Wang\"],[2016,\"Deep Survival Analysis\",\"The electronic health record (EHR) provides an unprecedented opportunity to\\\\nbuild actionable tools to support physicians at the point of care. In this\\\\npaper, we investigate survival analysis in the context of EHR data. We\\\\nintroduce deep survival analysis, a hierarchical generative approach to\\\\nsurvival analysis. It departs from previous approaches in two primary ways: (1)\\\\nall observations, including covariates, are modeled jointly conditioned on a\\\\nrich latent structure; and (2) the observations are aligned by their failure\\\\ntime, rather than by an arbitrary time zero as in traditional survival\\\\nanalysis. Further, it (3) scalably handles heterogeneous (continuous and\\\\ndiscrete) data types that occur in the EHR. We validate deep survival analysis\\\\nmodel by stratifying patients according to risk of developing coronary heart\\\\ndisease (CHD). Specifically, we study a dataset of 313,000 patients\\\\ncorresponding to 5.5 million months of observations. When compared to the\\\\nclinically validated Framingham CHD risk score, deep survival analysis is\\\\nsignificantly superior in stratifying patients according to their risk.\",\" Rajesh Ranganath,  Adler Perotte,  No\\\\u00e9mie Elhadad,  David Blei\"],[2011,\"Multiplicative Drift Analysis\",\"In this work, we introduce multiplicative drift analysis as a suitable way to\\\\nanalyze the runtime of randomized search heuristics such as evolutionary\\\\nalgorithms.\\\\n  We give a multiplicative version of the classical drift theorem. This allows\\\\neasier analyses in those settings where the optimization progress is roughly\\\\nproportional to the current distance to the optimum.\\\\n  To display the strength of this tool, we regard the classical problem how the\\\\n(1+1) Evolutionary Algorithm optimizes an arbitrary linear pseudo-Boolean\\\\nfunction. Here, we first give a relatively simple proof for the fact that any\\\\nlinear function is optimized in expected time $O(n \\\\\\\\log n)$, where $n$ is the\\\\nlength of the bit string. Afterwards, we show that in fact any such function is\\\\noptimized in expected time at most ${(1+o(1)) 1.39 \\\\\\\\euler n\\\\\\\\ln (n)}$, again\\\\nusing multiplicative drift analysis. We also prove a corresponding lower bound\\\\nof ${(1-o(1))e n\\\\\\\\ln(n)}$ which actually holds for all functions with a unique\\\\nglobal optimum.\\\\n  We further demonstrate how our drift theorem immediately gives natural proofs\\\\n(with better constants) for the best known runtime bounds for the (1+1)\\\\nEvolutionary Algorithm on combinatorial problems like finding minimum spanning\\\\ntrees, shortest paths, or Euler tours.\",\" Benjamin Doerr,  Daniel Johannsen,  Carola Winzen\"],[2017,\"Deep Generalized Canonical Correlation Analysis\",\"We present Deep Generalized Canonical Correlation Analysis (DGCCA) -- a\\\\nmethod for learning nonlinear transformations of arbitrarily many views of\\\\ndata, such that the resulting transformations are maximally informative of each\\\\nother. While methods for nonlinear two-view representation learning (Deep CCA,\\\\n(Andrew et al., 2013)) and linear many-view representation learning\\\\n(Generalized CCA (Horst, 1961)) exist, DGCCA is the first CCA-style multiview\\\\nrepresentation learning technique that combines the flexibility of nonlinear\\\\n(deep) representation learning with the statistical power of incorporating\\\\ninformation from many independent sources, or views. We present the DGCCA\\\\nformulation as well as an efficient stochastic optimization algorithm for\\\\nsolving it. We learn DGCCA representations on two distinct datasets for three\\\\ndownstream tasks: phonetic transcription from acoustic and articulatory\\\\nmeasurements, and recommending hashtags and friends on a dataset of Twitter\\\\nusers. We find that DGCCA representations soundly beat existing methods at\\\\nphonetic transcription and hashtag recommendation, and in general perform no\\\\nworse than standard linear many-view techniques.\",\" Adrian Benton,  Huda Khayrallah,  Biman Gujral,  Dee Ann Reisinger,  Sheng Zhang,  Raman Arora\"],[2012,\"Matrix Tile Analysis\",\"Many tasks require finding groups of elements in a matrix of numbers, symbols\\\\nor class likelihoods. One approach is to use efficient bi- or tri-linear\\\\nfactorization techniques including PCA, ICA, sparse matrix factorization and\\\\nplaid analysis. These techniques are not appropriate when addition and\\\\nmultiplication of matrix elements are not sensibly defined. More directly,\\\\nmethods like bi-clustering can be used to classify matrix elements, but these\\\\nmethods make the overly-restrictive assumption that the class of each element\\\\nis a function of a row class and a column class. We introduce a general\\\\ncomputational problem, `matrix tile analysis\\' (MTA), which consists of\\\\ndecomposing a matrix into a set of non-overlapping tiles, each of which is\\\\ndefined by a subset of usually nonadjacent rows and columns. MTA does not\\\\nrequire an algebra for combining tiles, but must search over discrete\\\\ncombinations of tile assignments. Exact MTA is a computationally intractable\\\\ninteger programming problem, but we describe an approximate iterative technique\\\\nand a computationally efficient sum-product relaxation of the integer program.\\\\nWe compare the effectiveness of these methods to PCA and plaid on hundreds of\\\\nrandomly generated tasks. Using double-gene-knockout data, we show that MTA\\\\nfinds groups of interacting yeast genes that have biologically-related\\\\nfunctions.\",\" Inmar Givoni,  Vincent Cheung,  Brendan J. Frey\"],[2013,\"Probabilistic Latent Semantic Analysis\",\"Probabilistic Latent Semantic Analysis is a novel statistical technique for\\\\nthe analysis of two-mode and co-occurrence data, which has applications in\\\\ninformation retrieval and filtering, natural language processing, machine\\\\nlearning from text, and in related areas. Compared to standard Latent Semantic\\\\nAnalysis which stems from linear algebra and performs a Singular Value\\\\nDecomposition of co-occurrence tables, the proposed method is based on a\\\\nmixture decomposition derived from a latent class model. This results in a more\\\\nprincipled approach which has a solid foundation in statistics. In order to\\\\navoid overfitting, we propose a widely applicable generalization of maximum\\\\nlikelihood model fitting by tempered EM. Our approach yields substantial and\\\\nconsistent improvements over Latent Semantic Analysis in a number of\\\\nexperiments.\",\" Thomas Hofmann\"],[2008,\"Supervised Exponential Family Principal Component Analysis via Convex Optimization\",\"Recently, supervised dimensionality reduction has been gaining attention, owing to the realization that data labels are often available and strongly suggest important underlying structures in the data. In this paper, we present a novel convex supervised dimensionality reduction approach based on exponential family PCA and provide a simple but novel form to project new testing data into the embedded space. This convex approach successfully avoids the local optima of the EM learning. Moreover, by introducing a sample-based multinomial approximation to exponential family models, it avoids the limitation of the prevailing Gaussian assumptions of standard PCA, and produces a kernelized formulation for nonlinear supervised dimensionality reduction. A training algorithm is then devised based on a subgradient bundle method, whose scalability can be gained through a coordinate descent procedure. The advantage of our global optimization approach is demonstrated by empirical results over both synthetic and real data.\",\"Lin Wu , Pierre Baldi , Zhilin Yang , Thang Luong , Russ Salakhutdinov , Quoc Le\"],[2014,\"Thematically Reinforced Explicit Semantic Analysis\",\"We present an extended, thematically reinforced version of Gabrilovich and\\\\nMarkovitch\\'s Explicit Semantic Analysis (ESA), where we obtain thematic\\\\ninformation through the category structure of Wikipedia. For this we first\\\\ndefine a notion of categorical tfidf which measures the relevance of terms in\\\\ncategories. Using this measure as a weight we calculate a maximal spanning tree\\\\nof the Wikipedia corpus considered as a directed graph of pages and categories.\\\\nThis tree provides us with a unique path of \\\\\"most related categories\\\\\" between\\\\neach page and the top of the hierarchy. We reinforce tfidf of words in a page\\\\nby aggregating it with categorical tfidfs of the nodes of these paths, and\\\\ndefine a thematically reinforced ESA semantic relatedness measure which is more\\\\nrobust than standard ESA and less sensitive to noise caused by out-of-context\\\\nwords. We apply our method to the French Wikipedia corpus, evaluate it through\\\\na text classification on a 37.5 MB corpus of 20 French newsgroups and obtain a\\\\nprecision increase of 9-10% compared with standard ESA.\",\" Yannis Haralambous,  Vitaly Klyuev\"],[2012,\"Formula-Based Probabilistic Inference\",\"Computing the probability of a formula given the probabilities or weights\\\\nassociated with other formulas is a natural extension of logical inference to\\\\nthe probabilistic setting. Surprisingly, this problem has received little\\\\nattention in the literature to date, particularly considering that it includes\\\\nmany standard inference problems as special cases. In this paper, we propose\\\\ntwo algorithms for this problem: formula decomposition and conditioning, which\\\\nis an exact method, and formula importance sampling, which is an approximate\\\\nmethod. The latter is, to our knowledge, the first application of model\\\\ncounting to approximate probabilistic inference. Unlike conventional\\\\nvariable-based algorithms, our algorithms work in the dual realm of logical\\\\nformulas. Theoretically, we show that our algorithms can greatly improve\\\\nefficiency by exploiting the structural information in the formulas.\\\\nEmpirically, we show that they are indeed quite powerful, often achieving\\\\nsubstantial performance gains over state-of-the-art schemes.\",\" Vibhav Gogate,  Pedro Domingos\"],[1996,\"Support Vector Regression Machines\",\"A  new  regression  technique  based  on  Vapnik\\'s  concept  of  support vectors  is  introduced.  We compare  support  vector  regression  (SVR) with  a  committee regression  technique  (bagging)  based  on  regression trees  and  ridge regression  done in  feature space.  On  the basis of these experiments,  it  is  expected  that  SVR  will  have  advantages  in  high dimensionality space because SVR optimization does not depend on the dimensionality of the input space. 1.  \",\"Adam Kowalczyk , Jacek Szymanski , Peter Bartlett , Robert Williamson , Edward Challis , David Barber\"],[2016,\"Sublinear Time Orthogonal Tensor Decomposition\",\"A recent work (Wang et. al., NIPS 2015) gives the fastest known algorithms for orthogonal tensor decomposition with provable guarantees. Their algorithm is based on computing sketches of the input tensor, which requires reading the entire input. We show in a number of cases one can achieve the same theoretical guarantees in sublinear time, i.e., even without reading most of the input tensor. Instead of using sketches to estimate inner products in tensor decomposition algorithms, we use importance sampling. To achieve sublinear time, we need to know the norms of tensor slices, and we show how to do this in a number of important cases. For symmetric tensors $ T = \\\\\\\\sum_{i=1}^k \\\\\\\\lambda_i u_i^{\\\\\\\\otimes p}$ with $\\\\\\\\lambda_i > 0$ for all i, we estimate such norms in sublinear time whenever p is even. For the important case of p = 3 and small values of k, we can also estimate such norms. For asymmetric tensors sublinear time is not possible in general, but we show if the tensor slice norms are just slightly below $\\\\\\\\| T \\\\\\\\|_F$ then sublinear time is again possible. One of the main strengths of our work is empirical - in a number of cases our algorithm is orders of magnitude faster than existing methods with the same accuracy.\",\"Yan Wu , Gregory Wayne , Karol Gregor , Timothy Lillicrap\"],[2005,\"Dynamic Social Network Analysis using Latent Space Models\",\"This paper explores two aspects of social network modeling. First,we generalize a successful static model of relationships into a dynamicmodel that accounts for friendships drifting over time. Second, we showhow to make it tractable to learn such models from data, even as thenumber of entities n gets large. The generalized model associates eachentity with a point in p-dimensional Euclidian latent space. The pointscan move as time progresses but large moves in latent space are improb-able. Observed links between entities are more likely if the entities areclose in latent space. We show how to make such a model tractable (sub-quadratic in the number of entities) by the use of appropriate kernel func-tions for similarity in latent space; the use of low dimensional kd-trees; anew ef(cid:2)cient dynamic adaptation of multidimensional scaling for a (cid:2)rstpass of approximate projection of entities into latent space; and an ef(cid:2)-cient conjugate gradient update rule for non-linear local optimization inwhich amortized time per entity during an update is O(log n). We useboth synthetic and real-world data on upto 11,000 entities which indicatelinear scaling in computation time and improved performance over fouralternative approaches. We also illustrate the system operating on twelveyears of NIPS co-publication data. We present a detailed version of thiswork in [1].1\",\"Francis Bach , Michael Jordan , Jianshu Chen , Chong Wang , Lin Xiao , Ji He , Lihong Li , Li Deng , Yifan Sun , Yaqi Duan , Hao Gong , Mengdi Wang\"],[2016,\"Mixed Linear Regression with Multiple Components\",\"In this paper, we study the mixed linear regression (MLR) problem, where the goal is to recover multiple underlying linear models from their unlabeled linear measurements. We propose a non-convex objective function which we show is {\\\\\\\\em locally strongly convex} in the neighborhood of the ground truth. We use a tensor method for initialization so that the initial models are in the local strong convexity region. We then employ general convex optimization algorithms to minimize the objective function. To the best of our knowledge, our approach provides first exact recovery guarantees for the MLR problem with $K \\\\\\\\geq 2$ components. Moreover,  our method has near-optimal computational complexity $\\\\\\\\tilde O (Nd)$ as well as near-optimal sample complexity $\\\\\\\\tilde O (d)$ for {\\\\\\\\em constant} $K$. Furthermore, we show that our non-convex formulation can be extended to solving the {\\\\\\\\em subspace clustering} problem as well. In particular, when initialized within a small constant distance to the true subspaces, our method converges to the global optima (and recovers true subspaces) in time {\\\\\\\\em linear} in the number of points. Furthermore, our empirical results indicate that even with random initialization, our approach converges to the global optima in linear time, providing speed-up of up to two orders of magnitude.\",null],[2012,\"Fast Marginalized Block Sparse Bayesian Learning Algorithm\",\"The performance of sparse signal recovery from noise corrupted,\\\\nunderdetermined measurements can be improved if both sparsity and correlation\\\\nstructure of signals are exploited. One typical correlation structure is the\\\\nintra-block correlation in block sparse signals. To exploit this structure, a\\\\nframework, called block sparse Bayesian learning (BSBL), has been proposed\\\\nrecently. Algorithms derived from this framework showed superior performance\\\\nbut they are not very fast, which limits their applications. This work derives\\\\nan efficient algorithm from this framework, using a marginalized likelihood\\\\nmaximization method. Compared to existing BSBL algorithms, it has close\\\\nrecovery performance but is much faster. Therefore, it is more suitable for\\\\nlarge scale datasets and applications requiring real-time implementation.\",\" Benyuan Liu,  Zhilin Zhang,  Hongqi Fan,  Qiang Fu\"],[2017,\"Social Media-based Substance Use Prediction\",\"In this paper, we demonstrate how the state-of-the-art machine learning and\\\\ntext mining techniques can be used to build effective social media-based\\\\nsubstance use detection systems. Since a substance use ground truth is\\\\ndifficult to obtain on a large scale, to maximize system performance, we\\\\nexplore different feature learning methods to take advantage of a large amount\\\\nof unsupervised social media data. We also demonstrate the benefit of using\\\\nmulti-view unsupervised feature learning to combine heterogeneous user\\\\ninformation such as Facebook `\\\\\"likes\\\\\" and \\\\\"status updates\\\\\" to enhance system\\\\nperformance. Based on our evaluation, our best models achieved 86% AUC for\\\\npredicting tobacco use, 81% for alcohol use and 84% for drug use, all of which\\\\nsignificantly outperformed existing methods. Our investigation has also\\\\nuncovered interesting relations between a user\\'s social media behavior (e.g.,\\\\nword usage) and substance use.\",\" Tao Ding,  Warren K. Bickel,  Shimei Pan\"],[2013,\"Matrix Approximation under Local Low-Rank Assumption\",\"Matrix approximation is a common tool in machine learning for building\\\\naccurate prediction models for recommendation systems, text mining, and\\\\ncomputer vision. A prevalent assumption in constructing matrix approximations\\\\nis that the partially observed matrix is of low-rank. We propose a new matrix\\\\napproximation model where we assume instead that the matrix is only locally of\\\\nlow-rank, leading to a representation of the observed matrix as a weighted sum\\\\nof low-rank matrices. We analyze the accuracy of the proposed local low-rank\\\\nmodeling. Our experiments show improvements in prediction accuracy in\\\\nrecommendation tasks.\",\" Joonseok Lee,  Seungyeon Kim,  Guy Lebanon,  Yoram Singer\"],[2018,\"Conditional Adversarial Domain Adaptation\",\"Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may struggle to align different domains of multimodal distributions that are native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. Experiments testify that the proposed approach exceeds the state-of-the-art results on five benchmark datasets.\",\"Pierre Monteiller , Sebastian Claici , Edward Chien , Farzaneh Mirzazadeh , Justin Solomon , Mikhail Yurochkin\"],[2016,\"Dynamic Probabilistic Network Based Human Action Recognition\",\"This paper examines use of dynamic probabilistic networks (DPN) for human\\\\naction recognition. The actions of lifting objects and walking in the room,\\\\nsitting in the room and neutral standing pose were used for testing the\\\\nclassification. The research used the dynamic interrelation between various\\\\ndifferent regions of interest (ROI) on the human body (face, body, arms, legs)\\\\nand the time series based events related to the these ROIs. This dynamic links\\\\nare then used to recognize the human behavioral aspects in the scene. First a\\\\nmodel is developed to identify the human activities in an indoor scene and this\\\\nmodel is dependent on the key features and interlinks between the various\\\\ndynamic events using DPNs. The sub ROI are classified with DPN to associate the\\\\ncombined interlink with a specific human activity. The recognition accuracy\\\\nperformance between indoor (controlled lighting conditions) is compared with\\\\nthe outdoor lighting conditions. The accuracy in outdoor scenes was lower than\\\\nthe controlled environment.\",\" Anne Veenendaal,  Eddie Jones,  Zhao Gang,  Elliot Daly,  Sumalini Vartak,  Rahul Patwardhan\"],[2016,\"Fast Supervised Discrete Hashing and its Analysis\",\"In this paper, we propose a learning-based supervised discrete hashing\\\\nmethod. Binary hashing is widely used for large-scale image retrieval as well\\\\nas video and document searches because the compact representation of binary\\\\ncode is essential for data storage and reasonable for query searches using\\\\nbit-operations. The recently proposed Supervised Discrete Hashing (SDH)\\\\nefficiently solves mixed-integer programming problems by alternating\\\\noptimization and the Discrete Cyclic Coordinate descent (DCC) method. We show\\\\nthat the SDH model can be simplified without performance degradation based on\\\\nsome preliminary experiments; we call the approximate model for this the \\\\\"Fast\\\\nSDH\\\\\" (FSDH) model. We analyze the FSDH model and provide a mathematically exact\\\\nsolution for it. In contrast to SDH, our model does not require an alternating\\\\noptimization algorithm and does not depend on initial values. FSDH is also\\\\neasier to implement than Iterative Quantization (ITQ). Experimental results\\\\ninvolving a large-scale database showed that FSDH outperforms conventional SDH\\\\nin terms of precision, recall, and computation time.\",\" Gou Koutaki,  Keiichiro Shirai,  Mitsuru Ambai\"],[2017,\"Deep adversarial neural decoding\",\"Here, we present a novel approach to solve the problem of reconstructing\\\\nperceived stimuli from brain responses by combining probabilistic inference\\\\nwith deep learning. Our approach first inverts the linear transformation from\\\\nlatent features to brain responses with maximum a posteriori estimation and\\\\nthen inverts the nonlinear transformation from perceived stimuli to latent\\\\nfeatures with adversarial training of convolutional neural networks. We test\\\\nour approach with a functional magnetic resonance imaging experiment and show\\\\nthat it can generate state-of-the-art reconstructions of perceived faces from\\\\nbrain activations.\",\" Ya\\\\u011fmur G\\\\u00fc\\\\u00e7l\\\\u00fct\\\\u00fcrk,  Umut G\\\\u00fc\\\\u00e7l\\\\u00fc,  Katja Seeliger,  Sander Bosch,  Rob van Lier,  Marcel van Gerven\"],[2017,\"Towards Evolutional Compression\",\"Compressing convolutional neural networks (CNNs) is essential for\\\\ntransferring the success of CNNs to a wide variety of applications to mobile\\\\ndevices. In contrast to directly recognizing subtle weights or filters as\\\\nredundant in a given CNN, this paper presents an evolutionary method to\\\\nautomatically eliminate redundant convolution filters. We represent each\\\\ncompressed network as a binary individual of specific fitness. Then, the\\\\npopulation is upgraded at each evolutionary iteration using genetic operations.\\\\nAs a result, an extremely compact CNN is generated using the fittest\\\\nindividual. In this approach, either large or small convolution filters can be\\\\nredundant, and filters in the compressed network are more distinct. In\\\\naddition, since the number of filters in each convolutional layer is reduced,\\\\nthe number of filter channels and the size of feature maps are also decreased,\\\\nnaturally improving both the compression and speed-up ratios. Experiments on\\\\nbenchmark deep CNN models suggest the superiority of the proposed algorithm\\\\nover the state-of-the-art compression methods.\",\" Yunhe Wang,  Chang Xu,  Jiayan Qiu,  Chao Xu,  Dacheng Tao\"],[2016,\"Surprisal-Driven Zoneout\",\"We propose a novel method of regularization for recurrent neural networks\\\\ncalled suprisal-driven zoneout. In this method, states zoneout (maintain their\\\\nprevious value rather than updating), when the suprisal (discrepancy between\\\\nthe last state\\'s prediction and target) is small. Thus regularization is\\\\nadaptive and input-driven on a per-neuron basis. We demonstrate the\\\\neffectiveness of this idea by achieving state-of-the-art bits per character of\\\\n1.31 on the Hutter Prize Wikipedia dataset, significantly reducing the gap to\\\\nthe best known highly-engineered compression methods.\",\" Kamil Rocki,  Tomasz Kornuta,  Tegan Maharaj\"],[2009,\"Granularity-Adaptive Proof Presentation\",\"When mathematicians present proofs they usually adapt their explanations to\\\\ntheir didactic goals and to the (assumed) knowledge of their addressees. Modern\\\\nautomated theorem provers, in contrast, present proofs usually at a fixed level\\\\nof detail (also called granularity). Often these presentations are neither\\\\nintended nor suitable for human use. A challenge therefore is to develop user-\\\\nand goal-adaptive proof presentation techniques that obey common mathematical\\\\npractice. We present a flexible and adaptive approach to proof presentation\\\\nthat exploits machine learning techniques to extract a model of the specific\\\\ngranularity of proof examples and employs this model for the automated\\\\ngeneration of further proofs at an adapted level of granularity.\",\" Marvin Schiller,  Christoph Benzmueller\"],[2014,\"CTBNCToolkit: Continuous Time Bayesian Network Classifier Toolkit\",\"Continuous time Bayesian network classifiers are designed for temporal\\\\nclassification of multivariate streaming data when time duration of events\\\\nmatters and the class does not change over time. This paper introduces the\\\\nCTBNCToolkit: an open source Java toolkit which provides a stand-alone\\\\napplication for temporal classification and a library for continuous time\\\\nBayesian network classifiers. CTBNCToolkit implements the inference algorithm,\\\\nthe parameter learning algorithm, and the structural learning algorithm for\\\\ncontinuous time Bayesian network classifiers. The structural learning algorithm\\\\nis based on scoring functions: the marginal log-likelihood score and the\\\\nconditional log-likelihood score are provided. CTBNCToolkit provides also an\\\\nimplementation of the expectation maximization algorithm for clustering\\\\npurpose. The paper introduces continuous time Bayesian network classifiers. How\\\\nto use the CTBNToolkit from the command line is described in a specific\\\\nsection. Tutorial examples are included to facilitate users to understand how\\\\nthe toolkit must be used. A section dedicate to the Java library is proposed to\\\\nhelp further code extensions.\",\" Daniele Codecasa,  Fabio Stella\"],[2017,\"TensorLog: Deep Learning Meets Probabilistic DBs\",\"We present an implementation of a probabilistic first-order logic called\\\\nTensorLog, in which classes of logical queries are compiled into differentiable\\\\nfunctions in a neural-network infrastructure such as Tensorflow or Theano. This\\\\nleads to a close integration of probabilistic logical reasoning with\\\\ndeep-learning infrastructure: in particular, it enables high-performance deep\\\\nlearning frameworks to be used for tuning the parameters of a probabilistic\\\\nlogic. Experimental results show that TensorLog scales to problems involving\\\\nhundreds of thousands of knowledge-base triples and tens of thousands of\\\\nexamples.\",\" William W. Cohen,  Fan Yang,  Kathryn Rivard Mazaitis\"],[2015,\"Robust Regression via Hard Thresholding\",\"We study the problem of Robust Least Squares Regression (RLSR) where several response variables can be adversarially corrupted. More specifically, for a data matrix X \\\\\\\\in \\\\\\\\R^{p x n} and an underlying model w*, the response vector is generated as y = X\\'w* + b where b \\\\\\\\in n is the corruption vector supported over at most C.n coordinates. Existing exact recovery results for RLSR focus solely on L1-penalty based convex formulations and impose relatively strict model assumptions such as requiring the corruptions b to be selected independently of X.In this work, we study a simple hard-thresholding algorithm called TORRENT which, under mild conditions on X, can recover w* exactly even if b corrupts the response variables in an adversarial manner, i.e. both the support and entries of b are selected adversarially after observing X and w*. Our results hold under deterministic assumptions which are satisfied if X is sampled from any sub-Gaussian distribution. Finally unlike existing results that apply only to a fixed w*, generated independently of X, our results are universal and hold for any w* \\\\\\\\in \\\\\\\\R^p.Next, we propose gradient descent-based extensions of TORRENT that can scale efficiently to large scale problems, such as high dimensional sparse recovery. and prove similar recovery guarantees for these extensions. Empirically we find TORRENT, and more so its extensions, offering significantly faster recovery than the state-of-the-art L1 solvers. For instance, even on moderate-sized datasets (with p = 50K) with around 40% corrupted responses, a variant of our proposed method called TORRENT-HYB is more than 20x faster than the best L1 solver.\",null],[1999,\"Agglomerative Information Bottleneck\",\"We  introduce a novel distributional clustering algorithm that max(cid:173)imizes  the  mutual  information  per  cluster  between  data and  giv(cid:173)en  categories.  This  algorithm  can  be considered  as  a  bottom  up hard  version  of  the  recently  introduced  \\\\\"Information  Bottleneck Method\\\\\".  The algorithm is  compared with the top-down soft  ver(cid:173)sion  of the  information  bottleneck  method  and  a  relationship  be(cid:173)tween the hard and soft results is established.  We  demonstrate the algorithm on the 20 Newsgroups data set.  For a subset of two news(cid:173)groups  we  achieve compression  by  3  orders  of magnitudes loosing only  10%  of the original mutual information. 1 \",\"Jyrki Kivinen , Manfred K. Warmuth , Krzysztof Choromanski , Tony Jebara , Kui Tang , Michele Donini , Luca Oneto , Shai Ben-David , John Shawe-Taylor , Massimiliano Pontil\"],[2012,\"Iterative Thresholding Algorithm for Sparse Inverse Covariance Estimation\",\"Sparse graphical modelling\\\\/inverse covariance selection is an important problem in machine learning and has seen significant advances in recent years. A major focus has been on methods which perform model selection in high dimensions. To this end, numerous convex $\\\\\\\\ell_1$ regularization approaches have been proposed in the literature. It is not however clear which of these methods are optimal in any well-defined sense. A major gap in this regard pertains to the rate of convergence of proposed optimization methods. To address this, an iterative thresholding algorithm for numerically solving the $\\\\\\\\ell_1$-penalized maximum likelihood problem for sparse inverse covariance estimation is presented. The proximal gradient method considered in this paper is shown to converge at a linear rate, a result which is the first of its kind for numerically solving the sparse inverse covariance estimation problem. The convergence rate is provided in closed form, and is related to the condition number of the optimal point. Numerical results demonstrating the proven rate of convergence are presented.\",null],[2012,\"Iterative Thresholding Algorithm for Sparse Inverse Covariance\\\\n  Estimation\",\"The L1-regularized maximum likelihood estimation problem has recently become\\\\na topic of great interest within the machine learning, statistics, and\\\\noptimization communities as a method for producing sparse inverse covariance\\\\nestimators. In this paper, a proximal gradient method (G-ISTA) for performing\\\\nL1-regularized covariance matrix estimation is presented. Although numerous\\\\nalgorithms have been proposed for solving this problem, this simple proximal\\\\ngradient method is found to have attractive theoretical and numerical\\\\nproperties. G-ISTA has a linear rate of convergence, resulting in an O(log e)\\\\niteration complexity to reach a tolerance of e. This paper gives eigenvalue\\\\nbounds for the G-ISTA iterates, providing a closed-form linear convergence\\\\nrate. The rate is shown to be closely related to the condition number of the\\\\noptimal point. Numerical convergence results and timing comparisons for the\\\\nproposed method are presented. G-ISTA is shown to perform very well, especially\\\\nwhen the optimal point is well-conditioned.\",\" Dominique Guillot,  Bala Rajaratnam,  Benjamin T. Rolfs,  Arian Maleki,  Ian Wong\"],[2016,\"Predicate Gradual Logic and Linguistics\",\"There are several major proposals for treating donkey anaphora such as\\\\ndiscourse representation theory and the likes, or E-Type theories and the\\\\nlikes. Every one of them works well for a set of specific examples that they\\\\nuse to demonstrate validity of their approaches. As I show in this paper,\\\\nhowever, they are not very generalisable and do not account for essentially the\\\\nsame problem that they remedy when it manifests in other examples. I propose\\\\nanother logical approach. I develoop logic that extends a recent, propositional\\\\ngradual logic, and show that it can treat donkey anaphora generally. I also\\\\nidentify and address a problem around the modern convention on existential\\\\nimport. Furthermore, I show that Aristotle\\'s syllogisms and conversion are\\\\nrealisable in this logic.\",\" Ryuta Arisaka\"],[2017,\"PCA-Initialized Deep Neural Networks Applied To Document Image Analysis\",\"In this paper, we present a novel approach for initializing deep neural\\\\nnetworks, i.e., by turning PCA into neural layers. Usually, the initialization\\\\nof the weights of a deep neural network is done in one of the three following\\\\nways: 1) with random values, 2) layer-wise, usually as Deep Belief Network or\\\\nas auto-encoder, and 3) re-use of layers from another network (transfer\\\\nlearning). Therefore, typically, many training epochs are needed before\\\\nmeaningful weights are learned, or a rather similar dataset is required for\\\\nseeding a fine-tuning of transfer learning. In this paper, we describe how to\\\\nturn a PCA into an auto-encoder, by generating an encoder layer of the PCA\\\\nparameters and furthermore adding a decoding layer. We analyze the\\\\ninitialization technique on real documents. First, we show that a PCA-based\\\\ninitialization is quick and leads to a very stable initialization. Furthermore,\\\\nfor the task of layout analysis we investigate the effectiveness of PCA-based\\\\ninitialization and show that it outperforms state-of-the-art random weight\\\\ninitialization methods.\",\" Mathias Seuret,  Michele Alberti,  Rolf Ingold,  Marcus Liwicki\"],[1995,\"Selective Attention for Handwritten Digit Recognition\",\"ompletely  parallel object  recognition  is  NP-complete.  Achieving a  recognizer  with  feasible  complexity  requires  a  compromise  be(cid:173)tween parallel and sequential processing  where a  system selectively focuses  on  parts  of a  given  image,  one  after  another.  Successive fixations  are  generated  to sample the  image and these  samples are processed  and abstracted  to  generate  a  temporal context  in which results are integrated over time.  A computational model based on a partially recurrent feedforward network is proposed and made cred(cid:173)ible  by  testing  on  the  real-world  problem  of recognition  of hand(cid:173)written  digits with encouraging results. 1 \",\"Klaus Obermayer , Lynne Kiorpes , Gary Blasdel , Grzegorz Swirszcz , Naoki Abe , Aurelie Lozano , Jinfeng Yi , Rong Jin , Shaili Jain , Tianbao Yang , Anil Jain\"],[2017,\"Neural Affine Grayscale Image Denoising\",\"We propose a new grayscale image denoiser, dubbed as Neural Affine Image\\\\nDenoiser (Neural AIDE), which utilizes neural network in a novel way. Unlike\\\\nother neural network based image denoising methods, which typically apply\\\\nsimple supervised learning to learn a mapping from a noisy patch to a clean\\\\npatch, we formulate to train a neural network to learn an \\\\\\\\emph{affine} mapping\\\\nthat gets applied to a noisy pixel, based on its context. Our formulation\\\\nenables both supervised training of the network from the labeled training\\\\ndataset and adaptive fine-tuning of the network parameters using the given\\\\nnoisy image subject to denoising. The key tool for devising Neural AIDE is to\\\\ndevise an estimated loss function of the MSE of the affine mapping, solely\\\\nbased on the noisy data. As a result, our algorithm can outperform most of the\\\\nrecent state-of-the-art methods in the standard benchmark datasets. Moreover,\\\\nour fine-tuning method can nicely overcome one of the drawbacks of the\\\\npatch-level supervised learning methods in image denoising; namely, a\\\\nsupervised trained model with a mismatched noise variance can be mostly\\\\ncorrected as long as we have the matched noise variance during the fine-tuning\\\\nstep.\",\" Sungmin Cha,  Taesup Moon\"],[2015,\"Listen, Attend and Spell\",\"We present Listen, Attend and Spell (LAS), a neural network that learns to\\\\ntranscribe speech utterances to characters. Unlike traditional DNN-HMM models,\\\\nthis model learns all the components of a speech recognizer jointly. Our system\\\\nhas two components: a listener and a speller. The listener is a pyramidal\\\\nrecurrent network encoder that accepts filter bank spectra as inputs. The\\\\nspeller is an attention-based recurrent network decoder that emits characters\\\\nas outputs. The network produces character sequences without making any\\\\nindependence assumptions between the characters. This is the key improvement of\\\\nLAS over previous end-to-end CTC models. On a subset of the Google voice search\\\\ntask, LAS achieves a word error rate (WER) of 14.1% without a dictionary or a\\\\nlanguage model, and 10.3% with language model rescoring over the top 32 beams.\\\\nBy comparison, the state-of-the-art CLDNN-HMM model achieves a WER of 8.0%.\",\" William Chan,  Navdeep Jaitly,  Quoc V. Le,  Oriol Vinyals\"],[2006,\"Learning Structural Equation Models for fMRI\",\"David McGonigleCentre for Functional Imaging StudiesUniversity of EdinburghStructural equation models can be seen as an extension of Gaussian belief net-works to cyclic graphs, and we show they can be understood generatively as themodel for the joint distribution of long term average equilibrium activity of Gaus-sian dynamic belief networks. Most use of structural equation models in fMRIinvolves postulating a particular structure and comparing learnt parameters acrossdifferent groups. In this paper it is argued that there are situations where priorsabout structure are not \\\\ufb01rm or exhaustive, and given suf\\\\ufb01cient data, it is worthinvestigating learning network structure as part of the approach to connectivityanalysis. First we demonstrate structure learning on a toy problem. We then showthat for particular fMRI data the simple models usually assumed are not supported.We show that is is possible to learn sensible structural equation models that canprovide modelling bene\\\\ufb01ts, but that are not necessarily going to be the same as atrue causal model, and suggest the combination of prior models and learning orthe use of temporal information from dynamic models may provide more bene\\\\ufb01tsthan learning structural equations alone.1 \",\"Joachim Giesen , Simon Spalinger , Bernhard Sch\\\\u00f6lkopf , Jian Wu , Matthias Poloczek , Andrew Wilson , Peter Frazier\"],[2017,\"Count-ception: Counting by Fully Convolutional Redundant Counting\",\"Counting objects in digital images is a process that should be replaced by\\\\nmachines. This tedious task is time consuming and prone to errors due to\\\\nfatigue of human annotators. The goal is to have a system that takes as input\\\\nan image and returns a count of the objects inside and justification for the\\\\nprediction in the form of object localization. We repose a problem, originally\\\\nposed by Lempitsky and Zisserman, to instead predict a count map which contains\\\\nredundant counts based on the receptive field of a smaller regression network.\\\\nThe regression network predicts a count of the objects that exist inside this\\\\nframe. By processing the image in a fully convolutional way each pixel is going\\\\nto be accounted for some number of times, the number of windows which include\\\\nit, which is the size of each window, (i.e., 32x32 = 1024). To recover the true\\\\ncount we take the average over the redundant predictions. Our contribution is\\\\nredundant counting instead of predicting a density map in order to average over\\\\nerrors. We also propose a novel deep neural network architecture adapted from\\\\nthe Inception family of networks called the Count-ception network. Together our\\\\napproach results in a 20% relative improvement (2.9 to 2.3 MAE) over the state\\\\nof the art method by Xie, Noble, and Zisserman in 2016.\",\" Joseph Paul Cohen,  Genevieve Boucher,  Craig A. Glastonbury,  Henry Z. Lo,  Yoshua Bengio\"],[2018,\"Assertion-based QA with Question-Aware Open Information Extraction\",\"We present assertion based question answering (ABQA), an open domain question\\\\nanswering task that takes a question and a passage as inputs, and outputs a\\\\nsemi-structured assertion consisting of a subject, a predicate and a list of\\\\narguments. An assertion conveys more evidences than a short answer span in\\\\nreading comprehension, and it is more concise than a tedious passage in\\\\npassage-based QA. These advantages make ABQA more suitable for human-computer\\\\ninteraction scenarios such as voice-controlled speakers. Further progress\\\\ntowards improving ABQA requires richer supervised dataset and powerful models\\\\nof text understanding. To remedy this, we introduce a new dataset called\\\\nWebAssertions, which includes hand-annotated QA labels for 358,427 assertions\\\\nin 55,960 web passages. To address ABQA, we develop both generative and\\\\nextractive approaches. The backbone of our generative approach is sequence to\\\\nsequence learning. In order to capture the structure of the output assertion,\\\\nwe introduce a hierarchical decoder that first generates the structure of the\\\\nassertion and then generates the words of each field. The extractive approach\\\\nis based on learning to rank. Features at different levels of granularity are\\\\ndesigned to measure the semantic relevance between a question and an assertion.\\\\nExperimental results show that our approaches have the ability to infer\\\\nquestion-aware assertions from a passage. We further evaluate our approaches by\\\\nincorporating the ABQA results as additional features in passage-based QA.\\\\nResults on two datasets show that ABQA features significantly improve the\\\\naccuracy on passage-based~QA.\",\" Zhao Yan,  Duyu Tang,  Nan Duan,  Shujie Liu,  Wendi Wang,  Daxin Jiang,  Ming Zhou,  Zhoujun Li\"],[2016,\"Optimal Generalized Decision Trees via Integer Programming\",\"Decision trees have been a very popular class of predictive models for\\\\ndecades due to their interpretability and good performance on categorical\\\\nfeatures. However, they are not always robust and tend to overfit the data.\\\\nAdditionally, if allowed to grow large, they lose interpretability. In this\\\\npaper, we present a novel mixed integer programming formulation to construct\\\\noptimal decision trees of specified size. We take special structure of\\\\ncategorical features into account and allow combinatorial decisions (based on\\\\nsubsets of values of such a feature) at each node. We show that very good\\\\naccuracy can be achieved with small trees using moderately-sized training sets.\\\\nThe optimization problems we solve are easily tractable with modern solvers.\",\" Oktay Gunluk,  Jayant Kalagnanam,  Matt Menickelly,  Katya Scheinberg\"],[2012,\"Dimension Reduction by Mutual Information Discriminant Analysis\",\"In the past few decades, researchers have proposed many discriminant analysis\\\\n(DA) algorithms for the study of high-dimensional data in a variety of\\\\nproblems. Most DA algorithms for feature extraction are based on\\\\ntransformations that simultaneously maximize the between-class scatter and\\\\nminimize the withinclass scatter matrices. This paper presents a novel DA\\\\nalgorithm for feature extraction using mutual information (MI). However, it is\\\\nnot always easy to obtain an accurate estimation for high-dimensional MI. In\\\\nthis paper, we propose an efficient method for feature extraction that is based\\\\non one-dimensional MI estimations. We will refer to this algorithm as mutual\\\\ninformation discriminant analysis (MIDA). The performance of this proposed\\\\nmethod was evaluated using UCI databases. The results indicate that MIDA\\\\nprovides robust performance over different data sets with different\\\\ncharacteristics and that MIDA always performs better than, or at least\\\\ncomparable to, the best performing algorithms.\",\" Ali Shadvar\"],[2016,\"Chess Player by Co-Evolutionary Algorithm\",\"A co-evolutionary algorithm (CA) based chess player is presented.\\\\nImplementation details of the algorithms, namely coding, population, variation\\\\noperators are described. The alpha-beta or mini-max like behaviour of the\\\\nplayer is achieved through two competitive or cooperative populations. Special\\\\nattention is given to the fitness function evaluation (the heart of the\\\\nsolution). Test results on algorithms vs. algorithms or human player is\\\\nprovided.\",\" Nuno Ramos,  Sergio Salgado,  Agostinho C Rosa\"],[2012,\"Local Markov Property for Models Satisfying Composition Axiom\",\"The local Markov condition for a DAG to be an independence map of a\\\\nprobability distribution is well known. For DAGs with latent variables,\\\\nrepresented as bi-directed edges in the graph, the local Markov property may\\\\ninvoke exponential number of conditional independencies. This paper shows that\\\\nthe number of conditional independence relations required may be reduced if the\\\\nprobability distributions satisfy the composition axiom. In certain types of\\\\ngraphs, only linear number of conditional independencies are required. The\\\\nresult has applications in testing linear structural equation models with\\\\ncorrelated errors.\",\" Changsung Kang,  Jin Tian\"],[1998,\"Learning Lie Groups for Invariant Visual Perception\",\"One  of the  most important problems  in  visual  perception is  that of visual  in(cid:173)variance:  how are objects perceived to be the same despite undergoing transfor(cid:173)mations such as translations, rotations or scaling?  In this paper, we describe a Bayesian method for learning invariances based on Lie group theory.  We show that previous approaches based on first-order Taylor series expansions of inputs can be regarded as special cases of the Lie group approach, the latter being ca(cid:173)pable of handling in principle arbitrarily large transfonnations. Using a matrix(cid:173)exponential based generative model of images,  we derive an unsupervised al(cid:173)gorithm for learning Lie group operators from  input data containing infinites(cid:173)imal transfonnations.  The on-line unsupervised learning algorithm maximizes the posterior probability of generating the training data.  We provide experimen(cid:173)tal results suggesting that the proposed method can learn Lie group operators for handling reasonably large I-D translations and 2-D rotations. 1  INTRODUCTION A fundamental problem faced by both biological and  machine vision systems is the recognition of familiar objects and patterns in the presence of transfonnations such as translations, rotations and scaling.  The importance ofthis problem was recognized early by visual scientists such as J. J. Gibson who hypothesized that \\\\\"constant perception depends on the ability of the individual to de(cid:173)tect the invariants\\\\\" [6].  Among computational neuroscientists, Pitts and McCulloch were perhaps the first to propose a method for perceptual invariance (\\\\\"knowing universals\\\\\") [12].  A number of other approaches have since been proposed [5, 7,  10], some relying on temporal sequences of input patterns undergoing transfonnations (e.g.  [4]) and others relying on modifications to the distance metric for comparing input images to stored templates (e.g. [15]). In this paper, we describe a Bayesian method for learning in variances based on the notion of contin(cid:173)uous transfonnations \\'and Lie group theory. We show that previous approaches based on first-order Taylor series expansions of images [1,  14]  can be regarded as special cases of the Lie group ap(cid:173)proach.  Approaches based on first-order models can account only for small transfonnations due to their assumption of a linear generative model for the transfonned images. The Lie approach on the other hand utilizes a matrix-exponential based generative model which can in principle handle arbitrarily large transfonnations once the correct transfonnation operators have been learned. Us(cid:173)ing Bayesian principles, we derive an on-line unsupervised algorithm for learning Lie group opera(cid:173)tors from input data containing infinitesimal transfonnations. Although Lie groups have previously \\\\\"This research was supported by the Alfred P.  Sloan Foundation. \\\\fLearning Lie Groups 8ll been used in visual perception [2], computer vision [16] and image processing [9], the question of whether it is possible to learn these groups directly from input data has remained open.  Our pre(cid:173)liminary experimental results suggest that in the two examined cases of l-D translations and 2-D rotations, the proposed method can learn the corresponding Lie group operators with a reasonably high degree of accuracy, allowing the  use of these learned operators in  transformation-invariant vision. 2  CONTINUOUS TRANSFORMATIONS AND LIE GROUPS Suppose we have a point (in general, a vector) 10 which is an element in a space F. Let T 10 denote a transformation of the point 10 to another point, say It. The transformation operator T  is completely specified by its actions on all points in the space F.  Suppose T  belongs to a family  of operators T.  We will be interested in the cases where I  is a group i.e. there exists a mapping f  : I  x  I  -t I  from pairs of transformations to another transformation such that (a) f  is associative, (b) there exists a  unique identity transformation, and (c) for every TEl, there exists a unique inverse transformation of T. These properties seem reasonable to expect in general for transformations on images. Continuous transformations are those which can be made infinitesimally small.  Due to their favor(cid:173)able properties as described below, we will be especially concerned with continuous transforma(cid:173)tion groups or Lie groups.  Continuity is associated with both the transformation operators T  and the group T.  Each TEl is assumed to implement a continuous mapping from F  -t F.  To be concrete, suppose T  is parameterized by  a  single real  number x.  Then, the group I  is continu(cid:173)ous if the function T{x)  :  1R  -t I  is continuous i.e.  any TEl is  the image of some x  E  1R and any continuous variation of x results in a continuous variation of T . Let T{O)  be equivalent to the identity transformation.  Then, as x  -t 0, the transformation T{x) gets arbitrarily close to identity.  Its effect on 10  can be written as  (to first order in x):  T{x)\\\\/o  ~ (1  + xG)\\\\/o  for some matrix G  which is known as the generator of the transformation group.  A macroscopic transfor(cid:173)mation It = I{x) = T{x)\\\\/o can be produced by chaining together a number of these infinitesimal transformations. For example, by dividing the parameter x into N  equal parts and performing each transformation in tum, we obtain: I{x)  = {1 + (X\\\\/N)G)N 10 (1) In the limit N  -t 00, this expression reduces to the matrix exponential equation: (2) where 10  is the initial or \\\\\"reference\\\\\" input.  Thus, each of the elements of our one-parameter Lie group can be written as:  T{x) = ezG \\\\u2022 The generatorG ofthe Lie group is related to the derivative ofT{x) with respect to x:  d~T =  GT.  This suggests an alternate way of deriving Equation 2. Consider the Taylor series expansion of a transformed input 1 (x) in terms of a previous input 1 (O): I{x) = ezG 10 d\\\\/{O) Jl. I{O)  x 2 I{x) = I{O) + ~x + ---;J;22 +... (3) where x denotes the relative transformation between I{x) and I{O).  Defining  d~1 = GI for some operator matrix G, we can rewrite Equation 3 as:  I{x)  = ezG 10  which is the same as equation 2 with 10  = I{O).  Thus, some previous approaches based on first-order Taylor series expansions [ 1,  14] can be viewed as special cases ofthe Lie group model. 3  LEARNING LIE TRANSFORMATION GROUPS Our goal is to learn the generators G of particular Lie transformation groups directly from input data containing examples of infinitesimal transformations.  Note that learning the generator of a trans(cid:173)formation effectively allows us to remain invariant to that transformation (see below). We assume that during natural temporal sequences of images containing transformations, there are \\\\\"small\\\\\" im(cid:173)age changes corresponding to deterministic sets of pixel changes that are independent of what the \\\\f812 R.  P.  N. Rao and D. L.  Ruderman (a)  1(.) N ........ l: FA111118lIon 01 Object Iclen...,. N ........ 2: EoIlnuIIIoa  01 Tronot ...... tIon (b) 1(0) (c) \\\\u2022 kG  k (  - ; ; - )  1(0) \\\\\"\\',i; .... ... ... \\\\u2022 \\\\u2022 \\'I \\\\\" \\\\u2022 Figure 1:  Network Architecture and Interpolation Function. (a) An implementation of the proposed ap(cid:173)proach to invariant vision involving two cooperating recurrent networks, one estimating transformations and the other estimating object  features.  The latter supplies the reference image 1(0) to the transformation net(cid:173)work.  (b)  A locally recurrent elaboration of the transformation network for implementing Equation 9.  The network computes e\\\\\",GI(O) = 1(0) + Lk(xkGk jk!)I(O). (c) The interpolation function Q used to generate training data (assuming periodic, band-limited signals). actual pixels are.  The rearrangements themselves are universal as in for example image transla(cid:173)tions. The question we address is:  can we learn the Lie group operator G given simply a series of \\\\\"before\\\\\" and \\\\\"after\\\\\" images? Let the n x 1 vector 1(0) be the \\\\\"before\\\\\" image and I(x) the \\\\\"after\\\\\" image containing the infinites(cid:173)imal transformation.  Then,  using results from the previous section,  we can write the following stochastic generative model for images: (4) where n is assumed to be a zero-mean Gaussian white noise process with variance (J2.  Since learn(cid:173)ing using this full exponential generative model is difficult due to multiple local minima, we restrict ourselves to transformations that are infinitesimal. The higher order terms then become negligible and we can rewrite the above equation in a more tractable form: I(x) =  e\\\\\",GI(O)  + n (5) where ~I =  I( x) - 1(0) is the difference image. Note that although this model is linear, the gener(cid:173)ator G learned using infinitesimal transformations is the same matrix that is used in the exponential model.  Thus, once learned, this matrix can be used to handle larger tr,ansformations as well (see experimental results). ~I =  xGI(O) + n Suppose we are given M  image pairs as data.  We wish to find the n  x  n matrix G and the trans(cid:173)formations x  which generated the data set.  To do so, we take a Bayesian maximum a posteriori approach using Gaussian priors on x  and G.  The negative log of the posterior probability of gen(cid:173)erating the data is given by: E  = -logP[G, xll(x), 1(0)] = 2(J2 (~I-xGI(O))T (~I-xGI(O))+ 2(J;x2 + 2gTC-lg  (6) where (J~ is the variance of the zero-mean Gaussian prior on x, g  is the n 2  x  1 vector form of G and C  is the covariance matrix associated with the Gaussian prior on G.  Extending this equation 1 1 1 \\\\fLearning Lie Groups 813 to multiple image data is accomplished straightforwardly by summing the data-driven tenn over the image pairs (we assume G is fixed for all images although the transfonnation x may vary). For the experiments, u, U x  and C  were chosen to be fixed scalar values but it may be possible to speed up learning and improve accuracy by choosing C  based on some knowledge of what we expect for infinitesimal image transfonnations (for example, we may define each entry in C  to be a function only of the distance between pixels associated with the entry and exploit the fact that C  needs to be symmetric; the efficacy of this choice is currently under investigation). The n  x  n  generator matrix G  can be learned in an unsupervised manner by perfonning gradient descent on E, thereby maximizing the posterior probability of generating the data: . T G  =  -a 8G = a(al - xGI(O\\\\u00bb(xl(O\\\\u00bb 8E - ac(G) (7) where a is a positive constant that governs the learning rate and c(G) is the n  x  n matrix fonn of the n 2  x 1 vector c- 1 g.  The learning rule for G above requires the value of x for the current image pair to be known.  We can estimate x by perfonning gradient descent on E with respect to x (using a fixed previously learned value for G): E  = f3(GI(O\\\\u00bbT(al - xGI(O\\\\u00bb  - ~x x  =  -f3 88x U x (8) The learning process thus involves alternating between the fast estimation of x  for the given image pair and the slower adaptation ofthe generator matrix G  using this x.  Figure 1 (a) depicts a pos(cid:173)sible network implementation of the proposed approach to invariant vision.  The implementation, which is reminiscent of the division oflabor between the dorsal and ventral streams in primate vi(cid:173)sual cortex [3], uses two parallel but cooperating networks, one estimating object identity and the other estimating object transfonnations.  The object network is based on a standard linear gener(cid:173)ative model of the fonn:  1(0)  =  Ur + DO  where U is a matrix of learned object \\\\\"features\\\\\" and r  is the feature vector for the object in 1(0) (see, for example, [11,  13]).  Perceptual constancy is achieved due to the fact that the estimate of object identity remains stable in the first network as the second network attempts to account for any transfonnations being induced in the image, appropri(cid:173)ately conveying the type of transfonnation being induced in its estimate for x  (see  [14]  for more details). The estimation rule for x given above is based on a first-order model (Equation 5) and is therefore useful only for estimating small (infinitesimal) transfonnations. A more general rule for estimating larger transfonnations is  obtaining by perfonning gradient descent on the optimization function given by the matrix-exponential generative model (Equation 4): x  =  -y(exGGI(O\\\\u00bb)T(I(x)  - exGI(O\\\\u00bb  _lx u; (9) Figure 1 (b) shows a locally recurrent network implementation of the matrix exponential compu(cid:173)tation required by the above equation. 4  EXPERIMENTAL RESULTS Training Data and Interpolation Function. For the purpose of evaluating the algorithm, we gen(cid:173)erated synthetic training data by subjecting a randomly generated image (containing unifonnly ran(cid:173)dom pixel intensities) to a known transfonnation.  Consider a given  I-D image 1(0)  with image pixels given by I (j), j  =  1, ... , N. To be able to continuously transfonn 1(0) sampled at discrete pixel locations by infinitesimal (sub-pixel) amounts, we need to employ an interpolation function. We make use of the Shannon-Whittaker theorem [8] stating that any band-limited signal I (j), with j  being any real number, is uniquely specified by its sufficiently close equally spaced discrete sam(cid:173)ples.  Assuming that our signal is periodic i.e.  I(j + N)  =  I(j) for all  j. the Shannon-Whittaker theorem in one dimension can be written as:  I(j) = E::~ I(m) E:-oo sinc[1r(j  - m  - Nr)] where  sinc[x]  =  sin(x)Jx.  After some algebraic  manipulation and  simplification,  this can  be reduced  to:  I(j)  =  E::~ I(m)Q(j  - m)  where  the  interpolation  function  Q  is  given  by: \\\\f814 R. P.  N.  Rao and D. L.  Ruderman Analytical Operator # 10 Real Imaginary (a) (b) Learned 0.5 0 -1  B~ -0.5  BIB Operator # 10 Ima~nary Real Figure 2:  Learned Lie Operators for 1\\\\u00b70 Translations.  (a)  Analytically-derived 20  x  20  Lie operator matrix G, operator for the  10th pixel (10th row of G), and plot of real and imaginary parts of the eigenvalues of G.  (b) Learned G matrix, 10th operator, and plot of eigenvalues of the learned matrix. Q(x)  =  (1\\\\/N)[1 + 2 L::~~-l cos(271\\'px\\\\/N)].  Figure 1 (c) shows this interpolation function.  To translate 1(0) by an infinitesimal amount x  E ~,we use:  I(j + x) = L:~:~ I(m)Q(j + x - m). Similarly, to rotate or translate 2-D images,  we use the 2-D analog of the above.  In addition to being able to generate images with known transformations, the interpolation function also allows one to derive an analytical expression for the Lie operator matrix directly from the derivative of Q. This allows us to evaluate the results oflearning. Figure 2 (a) shows the analytically-derived G matrix for  I-D infinitesimal translations of 20-pixel images (bright pixels = positive values, dark = negative).  Also shown alongside is one of the rows of G  (row 10) representing the Lie operator centered on pixel 10. Learning 1\\\\u00b7D Translations. Figure 2 (b) shows the results of using Equation 7 and 50, 000 training image pairs forlearning the generator matrix for I-D translations in 20-pixel images. The randomly generated first image of a training pair was translated left or right by 0.5 pixels (C- 1 = 0.0001 and learning rate a  = 0.4 was decreased by 1.0001 after each training pair).  Note that as expected for translations, the rows of the learned G matrix are identical except for a shift:  the same differential operator (shown in Figure 2 (b\\\\u00bb  is applied at each image location.  A comparison of the eigenval(cid:173)ues of the learned matrix with those of the analytical matrix (Figure 2) suggests that the learning algorithm was able to learn a reasonably good approximation of the true generator matrix (to within an arbitrary multiplicative scaling factor).  To further evaluate the learned matrix G, we ascertained whether G  could be used to generate arbitrary translations of a given reference image using Equa(cid:173)tion 2. The results are encouraging as shown in Figure 3 (a), although we have noticed a tendency for the appearance of some artifacts in translated images if there is significant high-frequency con(cid:173)tent in the reference image. Estimating Large Transformations. The learned generator matrix can be used to estimate large translations in images using Equation 9.  Unfortunately, the optimization function can contain local minima (Figure 3 (b\\\\u00bb . The local minima however tend to be shallow and of approximately the same value, with a unique well-defined global minimum. We therefore searched for the global minimum by performing gradient descent with several equally spaced starting values and picked the minimum of the estimated values after convergence. Figure 3 (c) shows results ofthis estimation process. Learning 2\\\\u00b7D Rotations.  We have also tested the learning algorithm in 2-D images using image plane rotations.  Training image pairs were generated by infinitesimally rotating images with ran(cid:173)dom pixel intensities 0.2 radians clockwise or counterclockwise. The learned operator matrix (for three different spatial scales) is shown in Figure 4 (a).  The accuracy of these matrices was tested \\\\fLearning Lie Groups 815 1(0) (a) I(x) x 1.5_,: 4.5_ \\\\\\\\ 7.5_  JO.5. r: 13.5 E I(x) -i 1(0) -I(x) x _-1.5 \\\\u00b7~ _-4.5 _-7.5 ~;~. -10.5 II -13.5 -_ .. _-(b) x = 19.9780 (20) x = -1.9780 (-2) x = 8.9787 (9) x = -7.9805 (-8) x = 2.9805 (3) x =-18.9805 (-19) x = 15.9775 (16) x = 26.9776 (27) x = 4.9774 (5) (e) Figure 3:  Generating and Estimating Large Transformations.  (a) An original reference image 1(0) was translated to varying degrees by using the learned generator matrix  G and  varying x  in Equation 2.  (b) The negative log likelihood optimization function for the matrix-exponential generative model (Equation 4) which was used for estimating large translations.  The globally minimum value  for x  was  found  by using gradient descent  with  multiple starting points.  (c) Comparison of estimated translation values with  actual values  (in parenthesis) for different pairs of reference (1(0)  and translated images (I(x)  shown in the form of a table. by using them in Equation 2 for various rotations x.  As shown in Figure 4 (b) for the 5  x  5 case, the learned matrix appears to be able to rotate a gi ven reference image between -1800  and + 1800 about an initial position (for the larger rotations, some minor artifacts appear near the edges). 5  CONCLUSIONS Our results suggest that it is possible for an unsupervised network to learn  visual  invariances by learning operators (or generators) for the corresponding Lie transformation groups.  An important issue is  how local minima can be  avoided during the estimation of large transformations.  Apart from performing multiple searches, one possibility is to use coarse-to-fine techniques, where trans(cid:173)formation estimates obtained at a coarse scale are used as starting points for estimating transforma(cid:173)tions at finer scales (see, for example, [1]).  A second possibility is to use stochastic techniques that exploit the specialized stucture of the optimization function (Figure  1 (c)).  Besides these direc(cid:173)tions of research, we are also investigating the use of structured priors on the generator matrix G to improve learning accuracy and speed.  A concurrent effort involves testing the approach on more realistic natural image sequences containing a richer variety of transformations.! References [1]  M. J.  Black and A.  D. Jepson.  Eigentracking:  Robust matching and tracking of articulated objects using a view-based representation.  In Proc.  of the Fourth European Conference on Computer Vision (ECCV), pages 329-342, 1996. [2]  P.  C. Dodwell.  The Lie transformation group model of visual perception.  Perception and Psychophysics, 34(1):1-16,1983. [3]  D. J. Felleman and D. C. Van Essen.  Distributed hierarchical processing in the primate cere(cid:173)bral cortex.  Cerebral Cortex,  1:1-47,1991. 1 The generative model in the case of multiple transformations is given by:  I(x) = eL;:l \\\\\",;Gi 1(0) + n where Gi  is the generator for the ith type of transformation and  Xi is the value of that transformation in the input image. \\\\f816 Initial . , \\\\u2022 \\' -.  \\\\u2022 Final ,.,. ..... R.  P.  N.  Rao and D.  L.  Ruderman (a) Figure 4:  Learned Lie Operators for 2-D Rotations.  (a) The initial and converged values of the Lie op(cid:173)erator matrix  for  2D rotations  at three different scales (3  x  3, 5 x  5 and 9  x  9).  (b) Examples of arbitrary rotations of a 5 x  5 reference image 1(0) generated by using the learned Lie operator matrix (although only results for integer-valued x  between -4 and 4 are shown, rotations can be generated for any real-valued x). [4]  P.  Foldiak.  Learning  in variance  from  transformation  sequences.  Neural  Computation, 3(2): 194-200, 1991. [5]  K. Fukushima.  Neocognitron:  A  self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position. Biological Cybernetics, 36: 193-202, 1980. [6]  J.J. Gibson. The Senses Considered as Perceptual Systems.  Houghton-Mifflin, Boston, 1966. [7]  Y.  LeCun,  B.  Boser,  J.  S.  Denker,  B.  Henderson,  R.  E.  Howard.  W.  Hubbard,  and  L. D. Jackel.  Backpropagation applied to handwritten zip code recognition.  Neural Computation, 1(4):541-551,1989. [8]  R.  J.  Marks II.  \",\"Andr\\\\u00e9 van Schaik , Eric Fragni\\\\u00e8re , Eric Vittoz , Richard Combes , Mohammad Sadegh Talebi Mazraeh Shahi , Alexandre Proutiere , marc lelarge\"],[2010,\"Deep Self-Taught Learning for Handwritten Character Recognition\",\"Recent theoretical and empirical work in statistical machine learning has\\\\ndemonstrated the importance of learning algorithms for deep architectures,\\\\ni.e., function classes obtained by composing multiple non-linear\\\\ntransformations. Self-taught learning (exploiting unlabeled examples or\\\\nexamples from other distributions) has already been applied to deep learners,\\\\nbut mostly to show the advantage of unlabeled examples. Here we explore the\\\\nadvantage brought by {\\\\\\\\em out-of-distribution examples}. For this purpose we\\\\ndeveloped a powerful generator of stochastic variations and noise processes for\\\\ncharacter images, including not only affine transformations but also slant,\\\\nlocal elastic deformations, changes in thickness, background images, grey level\\\\nchanges, contrast, occlusion, and various types of noise. The\\\\nout-of-distribution examples are obtained from these highly distorted images or\\\\nby including examples of object classes different from those in the target test\\\\nset. We show that {\\\\\\\\em deep learners benefit more from out-of-distribution\\\\nexamples than a corresponding shallow learner}, at least in the area of\\\\nhandwritten character recognition. In fact, we show that they beat previously\\\\npublished results and reach human-level performance on both handwritten digit\\\\nclassification and 62-class handwritten character recognition.\",\" Fr\\\\u00e9d\\\\u00e9ric Bastien,  Yoshua Bengio,  Arnaud Bergeron,  Nicolas Boulanger-Lewandowski,  Thomas Breuel,  Youssouf Chherawala,  Moustapha Cisse,  Myriam C\\\\u00f4t\\\\u00e9,  Dumitru Erhan,  Jeremy Eustache,  Xavier Glorot,  Xavier Muller,  Sylvain Pannetier Lebeuf,  Razvan Pascanu,  Salah Rifai,  Francois Savard,  Guillaume Sicard\"],[2012,\"Gray Image extraction using Fuzzy Logic\",\"Fuzzy systems concern fundamental methodology to represent and process\\\\nuncertainty and imprecision in the linguistic information. The fuzzy systems\\\\nthat use fuzzy rules to represent the domain knowledge of the problem are known\\\\nas Fuzzy Rule Base Systems (FRBS). On the other hand image segmentation and\\\\nsubsequent extraction from a noise-affected background, with the help of\\\\nvarious soft computing methods, are relatively new and quite popular due to\\\\nvarious reasons. These methods include various Artificial Neural Network (ANN)\\\\nmodels (primarily supervised in nature), Genetic Algorithm (GA) based\\\\ntechniques, intensity histogram based methods etc. providing an extraction\\\\nsolution working in unsupervised mode happens to be even more interesting\\\\nproblem. Literature suggests that effort in this respect appears to be quite\\\\nrudimentary. In the present article, we propose a fuzzy rule guided novel\\\\ntechnique that is functional devoid of any external intervention during\\\\nexecution. Experimental results suggest that this approach is an efficient one\\\\nin comparison to different other techniques extensively addressed in\\\\nliterature. In order to justify the supremacy of performance of our proposed\\\\ntechnique in respect of its competitors, we take recourse to effective metrics\\\\nlike Mean Squared Error (MSE), Mean Absolute Error (MAE), Peak Signal to Noise\\\\nRatio (PSNR).\",\" Koushik Mondal,  Paramartha Dutta,  Siddhartha Bhattacharyya\"],[2001,\"Optimising Synchronisation Times for Mobile Devices\",\"With the increasing number of users of mobile computing devices (e.g.  personal digital assistants) and the advent of third generation mobile phones, wireless communications are becoming increasingly important.  Many  applications  rely  on  the  device  maintaining  a replica  of a  data-structure which  is  stored on  a  server,  for  exam(cid:173)ple news databases, calendars and e-mail.  ill this paper we explore the question of the optimal strategy for synchronising such replicas. We utilise probabilistic models to represent how the data-structures evolve  and to model  user behaviour.  We  then formulate objective functions which can be minimised with respect to the synchronisa(cid:173)tion timings.  We demonstrate, using two real world data-sets, that a user can obtain more up-to-date information using our approach. 1 \",\"Jonathan Li , Andrew Barron\"],[2009,\"Information Distance in Multiples\",\"Information distance is a parameter-free similarity measure based on\\\\ncompression, used in pattern recognition, data mining, phylogeny, clustering,\\\\nand classification. The notion of information distance is extended from pairs\\\\nto multiples (finite lists). We study maximal overlap, metricity, universality,\\\\nminimal overlap, additivity, and normalized information distance in multiples.\\\\nWe use the theoretical notion of Kolmogorov complexity which for practical\\\\npurposes is approximated by the length of the compressed version of the file\\\\ninvolved, using a real-world compression program.\\\\n  {\\\\\\\\em Index Terms}-- Information distance, multiples, pattern recognition,\\\\ndata mining, similarity, Kolmogorov complexity\",\" Paul M. B. Vitanyi\"],[2017,\"Slim Embedding Layers for Recurrent Neural Language Models\",\"Recurrent neural language models are the state-of-the-art models for language\\\\nmodeling. When the vocabulary size is large, the space taken to store the model\\\\nparameters becomes the bottleneck for the use of recurrent neural language\\\\nmodels. In this paper, we introduce a simple space compression method that\\\\nrandomly shares the structured parameters at both the input and output\\\\nembedding layers of the recurrent neural language models to significantly\\\\nreduce the size of model parameters, but still compactly represent the original\\\\ninput and output embedding layers. The method is easy to implement and tune.\\\\nExperiments on several data sets show that the new method can get similar\\\\nperplexity and BLEU score results while only using a very tiny fraction of\\\\nparameters.\",\" Zhongliang Li,  Raymond Kulhanek,  Shaojun Wang,  Yunxin Zhao,  Shuang Wu\"],[2017,\"One Shot Joint Colocalization and Cosegmentation\",\"This paper presents a novel framework in which image cosegmentation and\\\\ncolocalization are cast into a single optimization problem that integrates\\\\ninformation from low level appearance cues with that of high level localization\\\\ncues in a very weakly supervised manner. In contrast to multi-task learning\\\\nparadigm that learns similar tasks using a shared representation, the proposed\\\\nframework leverages two representations at different levels and simultaneously\\\\ndiscriminates between foreground and background at the bounding box and\\\\nsuperpixel level using discriminative clustering. We show empirically that\\\\nconstraining the two problems at different scales enables the transfer of\\\\nsemantic localization cues to improve cosegmentation output whereas local\\\\nappearance based segmentation cues help colocalization. The unified framework\\\\noutperforms strong baseline approaches, of learning the two problems\\\\nseparately, by a large margin on four benchmark datasets. Furthermore, it\\\\nobtains competitive results compared to the state of the art for cosegmentation\\\\non two benchmark datasets and second best result for colocalization on Pascal\\\\nVOC 2007.\",\" Abhishek Sharma\"],[2013,\"Dealing with Uncertainty in Situation Assessment: towards a Symbolic\\\\n  Approach\",\"The situation assessment problem is considered, in terms of object,\\\\ncondition, activity, and plan recognition, based on data coming from the\\\\nreal-word {em via} various sensors. It is shown that uncertainty issues are\\\\nlinked both to the models and to the matching algorithm. Three different types\\\\nof uncertainties are identified, and within each one, the numerical and the\\\\nsymbolic cases are distinguished. The emphasis is then put on purely symbolic\\\\nuncertainties: it is shown that they can be dealt with within a purely symbolic\\\\nframework resulting from a transposition of classical numerical estimation\\\\ntools.\",\" Charles Castel,  Corine Cossart,  Catherine Tessier\"],[2017,\"Incorporating Syntactic Uncertainty in Neural Machine Translation with\\\\n  Forest-to-Sequence Model\",\"Incorporating syntactic information in Neural Machine Translation models is a\\\\nmethod to compensate their requirement for a large amount of parallel training\\\\ntext, especially for low-resource language pairs. Previous works on using\\\\nsyntactic information provided by (inevitably error-prone) parsers has been\\\\npromising. In this paper, we propose a forest-to-sequence Attentional Neural\\\\nMachine Translation model to make use of exponentially many parse trees of the\\\\nsource sentence to compensate for the parser errors. Our method represents the\\\\ncollection of parse trees as a packed forest, and learns a neural attentional\\\\ntransduction model from the forest to the target sentence. Experiments on\\\\nEnglish to German, Chinese and Persian translation show the superiority of our\\\\nmethod over the tree-to-sequence and vanilla sequence-to-sequence neural\\\\ntranslation models.\",\" Poorya Zaremoodi,  Gholamreza Haffari\"],[2015,\"Neuroprosthetic decoder training as imitation learning\",\"Neuroprosthetic brain-computer interfaces function via an algorithm which\\\\ndecodes neural activity of the user into movements of an end effector, such as\\\\na cursor or robotic arm. In practice, the decoder is often learned by updating\\\\nits parameters while the user performs a task. When the user\\'s intention is not\\\\ndirectly observable, recent methods have demonstrated value in training the\\\\ndecoder against a surrogate for the user\\'s intended movement. We describe how\\\\ntraining a decoder in this way is a novel variant of an imitation learning\\\\nproblem, where an oracle or expert is employed for supervised training in lieu\\\\nof direct observations, which are not available. Specifically, we describe how\\\\na generic imitation learning meta-algorithm, dataset aggregation (DAgger, [1]),\\\\ncan be adapted to train a generic brain-computer interface. By deriving\\\\nexisting learning algorithms for brain-computer interfaces in this framework,\\\\nwe provide a novel analysis of regret (an important metric of learning\\\\nefficacy) for brain-computer interfaces. This analysis allows us to\\\\ncharacterize the space of algorithmic variants and bounds on their regret\\\\nrates. Existing approaches for decoder learning have been performed in the\\\\ncursor control setting, but the available design principles for these decoders\\\\nare such that it has been impossible to scale them to naturalistic settings.\\\\nLeveraging our findings, we then offer an algorithm that combines imitation\\\\nlearning with optimal control, which should allow for training of arbitrary\\\\neffectors for which optimal control can generate goal-oriented control. We\\\\ndemonstrate this novel and general BCI algorithm with simulated neuroprosthetic\\\\ncontrol of a 26 degree-of-freedom model of an arm, a sophisticated and\\\\nrealistic end effector.\",\" Josh Merel,  David Carlson,  Liam Paninski,  John P. Cunningham\"]]}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "7KRB7CzMx9eG",
        "outputId": "28de01c9-24b6-414f-f95f-5516a2665ebd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       year                                              title  \\\n",
              "16372  2017           Contrastive Principal Component Analysis   \n",
              "17462  2012    Generalized Principal Component Analysis (GPCA)   \n",
              "3172   2008         Robust Kernel Principal Component Analysis   \n",
              "4641   2013                      Similarity Component Analysis   \n",
              "1597   2000         Sparse Kernel Principal Component Analysis   \n",
              "...     ...                                                ...   \n",
              "26835  2017  Slim Embedding Layers for Recurrent Neural Lan...   \n",
              "17879  2017   One Shot Joint Colocalization and Cosegmentation   \n",
              "28347  2013  Dealing with Uncertainty in Situation Assessme...   \n",
              "26812  2017  Incorporating Syntactic Uncertainty in Neural ...   \n",
              "20682  2015  Neuroprosthetic decoder training as imitation ...   \n",
              "\n",
              "                                                abstract  \\\n",
              "16372  We present a new technique called contrastive ...   \n",
              "17462  This paper presents an algebro-geometric solut...   \n",
              "3172   Kernel Principal Component Analysis (KPCA) is ...   \n",
              "4641   Measuring similarity is crucial to many learni...   \n",
              "1597   'Kernel'  principal  component  analysis  (PCA...   \n",
              "...                                                  ...   \n",
              "26835  Recurrent neural language models are the state...   \n",
              "17879  This paper presents a novel framework in which...   \n",
              "28347  The situation assessment problem is considered...   \n",
              "26812  Incorporating syntactic information in Neural ...   \n",
              "20682  Neuroprosthetic brain-computer interfaces func...   \n",
              "\n",
              "                                                 auhtors  \n",
              "16372   Abubakar Abid,  Martin J. Zhang,  Vivek K. Ba...  \n",
              "17462                Rene Vidal,  Yi Ma,  Shankar Sastry  \n",
              "3172                                                 NaN  \n",
              "4641                                                 NaN  \n",
              "1597                         Charles Isbell , Paul Viola  \n",
              "...                                                  ...  \n",
              "26835   Zhongliang Li,  Raymond Kulhanek,  Shaojun Wa...  \n",
              "17879                                    Abhishek Sharma  \n",
              "28347   Charles Castel,  Corine Cossart,  Catherine T...  \n",
              "26812              Poorya Zaremoodi,  Gholamreza Haffari  \n",
              "20682   Josh Merel,  David Carlson,  Liam Paninski,  ...  \n",
              "\n",
              "[71 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3af90994-154b-4ab4-a154-67a9b50675a5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>year</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>auhtors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16372</th>\n",
              "      <td>2017</td>\n",
              "      <td>Contrastive Principal Component Analysis</td>\n",
              "      <td>We present a new technique called contrastive ...</td>\n",
              "      <td>Abubakar Abid,  Martin J. Zhang,  Vivek K. Ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17462</th>\n",
              "      <td>2012</td>\n",
              "      <td>Generalized Principal Component Analysis (GPCA)</td>\n",
              "      <td>This paper presents an algebro-geometric solut...</td>\n",
              "      <td>Rene Vidal,  Yi Ma,  Shankar Sastry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3172</th>\n",
              "      <td>2008</td>\n",
              "      <td>Robust Kernel Principal Component Analysis</td>\n",
              "      <td>Kernel Principal Component Analysis (KPCA) is ...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4641</th>\n",
              "      <td>2013</td>\n",
              "      <td>Similarity Component Analysis</td>\n",
              "      <td>Measuring similarity is crucial to many learni...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1597</th>\n",
              "      <td>2000</td>\n",
              "      <td>Sparse Kernel Principal Component Analysis</td>\n",
              "      <td>'Kernel'  principal  component  analysis  (PCA...</td>\n",
              "      <td>Charles Isbell , Paul Viola</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26835</th>\n",
              "      <td>2017</td>\n",
              "      <td>Slim Embedding Layers for Recurrent Neural Lan...</td>\n",
              "      <td>Recurrent neural language models are the state...</td>\n",
              "      <td>Zhongliang Li,  Raymond Kulhanek,  Shaojun Wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17879</th>\n",
              "      <td>2017</td>\n",
              "      <td>One Shot Joint Colocalization and Cosegmentation</td>\n",
              "      <td>This paper presents a novel framework in which...</td>\n",
              "      <td>Abhishek Sharma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28347</th>\n",
              "      <td>2013</td>\n",
              "      <td>Dealing with Uncertainty in Situation Assessme...</td>\n",
              "      <td>The situation assessment problem is considered...</td>\n",
              "      <td>Charles Castel,  Corine Cossart,  Catherine T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26812</th>\n",
              "      <td>2017</td>\n",
              "      <td>Incorporating Syntactic Uncertainty in Neural ...</td>\n",
              "      <td>Incorporating syntactic information in Neural ...</td>\n",
              "      <td>Poorya Zaremoodi,  Gholamreza Haffari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20682</th>\n",
              "      <td>2015</td>\n",
              "      <td>Neuroprosthetic decoder training as imitation ...</td>\n",
              "      <td>Neuroprosthetic brain-computer interfaces func...</td>\n",
              "      <td>Josh Merel,  David Carlson,  Liam Paninski,  ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3af90994-154b-4ab4-a154-67a9b50675a5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3af90994-154b-4ab4-a154-67a9b50675a5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3af90994-154b-4ab4-a154-67a9b50675a5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test(text:None):\n",
        "  print(\"Executing\")\n",
        "  t0 = time.time()\n",
        "  output = pd.DataFrame()\n",
        "  if text == None:\n",
        "    query_text_test = \"HUMAN BRAIN MIMICS\"\n",
        "  else:\n",
        "    query_text_test = text\n",
        "  \n",
        "  query_embedding=convert_to_embedding(query_text_test)\n",
        "  indices_data_title=list(map(int,Lsh_data_title.fetch(query_embedding)))\n",
        "\n",
        "  sorted_title_indices=Lsh_data_title.ShowData(data_title_embeddings.iloc[indices_data_title].to_numpy(),np.array([query_embedding]))\n",
        "  output = dataset.iloc[sorted_title_indices]\n",
        "  print(\"Time taken :\",format_time(time.time() - t0))\n",
        "  out_json = output.to_json(orient='split')  \n",
        "  return(out_json)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3ilktI22e2N",
        "outputId": "b0187b93-8d4e-4eeb-dad9-3c5375b3ff93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Variational inference is a scalable technique for approximate Bayesian inference.  Deriving variational inference algorithms requires tedious model-specific calculations; this makes it difficult for non-experts to use.  We propose an automatic variational inference algorithm, automatic differentiation variational inference (ADVI); we implement it in Stan (code available), a probabilistic programming system.  In ADVI the user provides a Bayesian model and a dataset, nothing else.  We make no conjugacy assumptions and support a broad class of models. The algorithm automatically determines an appropriate variational family and optimizes the variational objective. We compare ADVI to MCMC sampling across hierarchical generalized linear models, nonconjugate matrix factorization, and a mixture model. We train the mixture model on a quarter million images.  With ADVI we can use variational inference on any model we write in Stan.',\n",
              "       'Behavioral cloning reduces policy learning to supervised learning by training a discriminative model to predict expert actions given observations. Such discriminative models are non-causal: the training procedure is unaware of the causal structure of the interaction between the expert and the environment. We point out that ignoring causality is particularly damaging because of the distributional shift in imitation learning. In particular, it leads to a counter-intuitive \"causal misidentification\" phenomenon: access to more information can yield worse performance. We investigate how this problem arises, and propose a solution to combat it through targeted interventions---either environment interaction or expert queries---to determine the correct causal model. We show that causal misidentification occurs in several benchmark control domains as well as realistic driving settings, and validate our solution against DAgger and other baselines and ablations.',\n",
              "       \"Structured prediction can be thought of as a simultaneous prediction of multiple labels. This is often done by maximizing a score function on the space of labels, which decomposes as a sum of pairwise and unary potentials.The above is naturally modeled with a graph, where edges and vertices are related to pairwise and unary potentials, respectively.We consider the generative process proposed by Globerson et al. (2015) and apply it to general connected graphs.We analyze the structural conditions of the graph that allow for the exact recovery of the labels.Our results show that exact recovery is possible and achievable in polynomial time for a large class of graphs.In particular, we show that graphs that are bad expanders can be exactly recovered by adding small edge perturbations coming from the \\\\Erdos-\\\\Renyi model.Finally, as a byproduct of our analysis, we provide an extension of Cheeger's inequality.\",\n",
              "       'We study linear approximate value iteration (LAVI) with a generative model. While linear models may accurately represent the optimal value function using a few parameters, several empirical and theoretical studies show the combination of least-squares projection with the Bellman operator may be expansive, thus leading LAVI to amplify errors over iterations and eventually diverge. We introduce an algorithm that approximates value functions by combining Q-values estimated at a set of \\\\textit{anchor} states. Our algorithm tries to balance the generalization and compactness of linear methods with the small amplification of errors typical of interpolation methods. We prove that if the features at any state can be represented as a convex combination of features at the anchor points, then errors are propagated linearly over iterations (instead of exponentially) and our method achieves a polynomial sample complexity bound in the horizon and the number of anchor points. These findings are confirmed in preliminary simulations in a number of simple problems where a traditional least-square LAVI method diverges.',\n",
              "       'We present a conditional temporal probabilistic framework for recon-structing 3D human motion in monocular video based on descriptors en-coding image silhouette observations. For computational efﬁciency werestrict visual inference to low-dimensional kernel induced non-linearstate spaces. Our methodology (kBME) combines kernel PCA-basednon-linear dimensionality reduction (kPCA) and Conditional BayesianMixture of Experts (BME) in order to learn complex multivalued pre-dictors between observations and model hidden states. This is necessaryfor accurate, inverse, visual perception inferences, where several proba-ble, distant 3D solutions exist due to noise or the uncertainty of monoc-ular perspective projection. Low-dimensional models are appropriatebecause many visual processes exhibit strong non-linear correlations inboth the image observations and the target, hidden state variables. Thelearned predictors are temporally combined within a conditional graphi-cal model in order to allow a principled propagation of uncertainty. Westudy several predictors and empirically show that the proposed algo-rithm positively compares with techniques based on regression, KernelDependency Estimation (KDE) or PCA alone, and gives results competi-tive to those of high-dimensional mixture predictors at a fraction of theircomputational cost. We show that the method successfully reconstructsthe complex 3D motion of humans in real monocular video sequences.1'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hNh-Mic7yjnV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}