{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oca773WVerG4",
        "outputId": "5cf21569-d0b6-4eeb-ecd1-d078721d903e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install transformers "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2Kgxs3eZ58",
        "outputId": "362b1f2e-385d-4262-e2ab-96eb55c47271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.24.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 44.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.2 transformers-4.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otE3fF9VcSee",
        "outputId": "8994cf8e-c2ff-4c2e-eb00-0cd5b10d3f5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.7.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/AI5 MLOPS/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wASH-xTufWjT",
        "outputId": "2fe96a4d-78ff-4674-c5df-8ece0b216483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1IBzU3wncSMdMkz8e2pEnfntllTMVQ3O0/AI5 MLOPS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 895
        },
        "id": "mn67ZUKIeSH6",
        "outputId": "c151fc1c-d38b-49a4-b997-ecfe28e5feb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Shape : (9313, 6)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for \" HUMAN BRAIN MIMICS \"query\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  title  \\\n",
              "6077                 Stochastic Online AUC Maximization   \n",
              "8458                            Levenshtein Transformer   \n",
              "3042                            Supervised Topic Models   \n",
              "6556                 Triple Generative Adversarial Nets   \n",
              "1968                                       Hyperkernels   \n",
              "2475    Fast Gaussian Process Regression using KD-Trees   \n",
              "37    SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENT...   \n",
              "38    Simulations Suggest Information Processing Rol...   \n",
              "60                    HIGH DENSITY ASSOCIATIVE MEMORIES   \n",
              "41    Discovering Structure from Motion in Monkey, M...   \n",
              "\n",
              "                                               abstract   cos_sim  \n",
              "6077  Area under ROC (AUC) is a metric which is wide...  0.991502  \n",
              "8458  Modern neural sequence generation models are b...  0.991375  \n",
              "3042  We introduce supervised latent Dirichlet alloc...  0.991162  \n",
              "6556  Generative Adversarial Nets (GANs) have shown ...  0.991110  \n",
              "1968  We consider the problem of choosing a kernel s...  0.990959  \n",
              "2475                                                 1   0.961937  \n",
              "37    he brain works in a state-dependent manner: pr...  0.949969  \n",
              "38     computer model of the hippocampal pyramidal c...  0.929786  \n",
              "60              rom a description of desired properties  0.900976  \n",
              "41    he ability to obtain three-dimensional structu...  0.866808  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-073daea0-8d08-49d9-803f-b762b9552704\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6077</th>\n",
              "      <td>Stochastic Online AUC Maximization</td>\n",
              "      <td>Area under ROC (AUC) is a metric which is wide...</td>\n",
              "      <td>0.991502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8458</th>\n",
              "      <td>Levenshtein Transformer</td>\n",
              "      <td>Modern neural sequence generation models are b...</td>\n",
              "      <td>0.991375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3042</th>\n",
              "      <td>Supervised Topic Models</td>\n",
              "      <td>We introduce supervised latent Dirichlet alloc...</td>\n",
              "      <td>0.991162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6556</th>\n",
              "      <td>Triple Generative Adversarial Nets</td>\n",
              "      <td>Generative Adversarial Nets (GANs) have shown ...</td>\n",
              "      <td>0.991110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1968</th>\n",
              "      <td>Hyperkernels</td>\n",
              "      <td>We consider the problem of choosing a kernel s...</td>\n",
              "      <td>0.990959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>Fast Gaussian Process Regression using KD-Trees</td>\n",
              "      <td>1</td>\n",
              "      <td>0.961937</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENT...</td>\n",
              "      <td>he brain works in a state-dependent manner: pr...</td>\n",
              "      <td>0.949969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Simulations Suggest Information Processing Rol...</td>\n",
              "      <td>computer model of the hippocampal pyramidal c...</td>\n",
              "      <td>0.929786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>HIGH DENSITY ASSOCIATIVE MEMORIES</td>\n",
              "      <td>rom a description of desired properties</td>\n",
              "      <td>0.900976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Discovering Structure from Motion in Monkey, M...</td>\n",
              "      <td>he ability to obtain three-dimensional structu...</td>\n",
              "      <td>0.866808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-073daea0-8d08-49d9-803f-b762b9552704')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-073daea0-8d08-49d9-803f-b762b9552704 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-073daea0-8d08-49d9-803f-b762b9552704');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken : 0:00:07\n",
            "Results for \" VLSI neural network \"query\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                  title  \\\n",
              "8819        Variational Graph Recurrent Neural Networks   \n",
              "7209               Reversible Recurrent Neural Networks   \n",
              "7911     Hyperbolic Graph Convolutional Neural Networks   \n",
              "7978                   Hyperbolic Graph Neural Networks   \n",
              "6054               Doubly Convolutional Neural Networks   \n",
              "2475    Fast Gaussian Process Regression using KD-Trees   \n",
              "37    SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENT...   \n",
              "38    Simulations Suggest Information Processing Rol...   \n",
              "60                    HIGH DENSITY ASSOCIATIVE MEMORIES   \n",
              "41    Discovering Structure from Motion in Monkey, M...   \n",
              "\n",
              "                                               abstract   cos_sim  \n",
              "8819  Representation learning over graph structured ...  0.994412  \n",
              "7209  Recurrent neural networks (RNNs) provide state...  0.994219  \n",
              "7911  Graph convolutional neural networks (GCNs) emb...  0.994154  \n",
              "7978  Learning from graph-structured data is an impo...  0.994024  \n",
              "6054  Building large models with parameter sharing a...  0.993757  \n",
              "2475                                                 1   0.958352  \n",
              "37    he brain works in a state-dependent manner: pr...  0.947613  \n",
              "38     computer model of the hippocampal pyramidal c...  0.934392  \n",
              "60              rom a description of desired properties  0.901424  \n",
              "41    he ability to obtain three-dimensional structu...  0.871801  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7156572-5f28-42ae-aa38-119855d06334\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>cos_sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8819</th>\n",
              "      <td>Variational Graph Recurrent Neural Networks</td>\n",
              "      <td>Representation learning over graph structured ...</td>\n",
              "      <td>0.994412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7209</th>\n",
              "      <td>Reversible Recurrent Neural Networks</td>\n",
              "      <td>Recurrent neural networks (RNNs) provide state...</td>\n",
              "      <td>0.994219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7911</th>\n",
              "      <td>Hyperbolic Graph Convolutional Neural Networks</td>\n",
              "      <td>Graph convolutional neural networks (GCNs) emb...</td>\n",
              "      <td>0.994154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7978</th>\n",
              "      <td>Hyperbolic Graph Neural Networks</td>\n",
              "      <td>Learning from graph-structured data is an impo...</td>\n",
              "      <td>0.994024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054</th>\n",
              "      <td>Doubly Convolutional Neural Networks</td>\n",
              "      <td>Building large models with parameter sharing a...</td>\n",
              "      <td>0.993757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>Fast Gaussian Process Regression using KD-Trees</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENT...</td>\n",
              "      <td>he brain works in a state-dependent manner: pr...</td>\n",
              "      <td>0.947613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Simulations Suggest Information Processing Rol...</td>\n",
              "      <td>computer model of the hippocampal pyramidal c...</td>\n",
              "      <td>0.934392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>HIGH DENSITY ASSOCIATIVE MEMORIES</td>\n",
              "      <td>rom a description of desired properties</td>\n",
              "      <td>0.901424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Discovering Structure from Motion in Monkey, M...</td>\n",
              "      <td>he ability to obtain three-dimensional structu...</td>\n",
              "      <td>0.871801</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7156572-5f28-42ae-aa38-119855d06334')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7156572-5f28-42ae-aa38-119855d06334 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7156572-5f28-42ae-aa38-119855d06334');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken : 0:00:13\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "import json\n",
        "\n",
        "import torch\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "import torch.optim as optim\n",
        "from transformers import BertTokenizer,  BertForMaskedLM ,AdamW ,BertConfig \n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def load_data():\n",
        "  data  = pd.read_csv(\"papers_with_abstract.csv\")\n",
        "  print(\"Data Shape :\" , data.shape)\n",
        "\n",
        "  data = data.drop([\"Unnamed: 0\",\"source_id\"],axis = 1)\n",
        "  data['abstract'] = data['abstract'].replace(r'\\n', '', regex=True)\n",
        "  data['full_text'] = data['full_text'].replace(r'\\n', '', regex=True)\n",
        "  return data \n",
        "\n",
        "def model_load(FILE = None):\n",
        "\n",
        "  device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "  # Get the SciBERT pretrained model path from Allen AI repo\n",
        "  pretrained_model = 'allenai/scibert_scivocab_uncased'\n",
        "\n",
        "  # Get the tokenizer from the previous path\n",
        "  sciBERT_tokenizer = BertTokenizer.from_pretrained(pretrained_model, \n",
        "                                            do_lower_case=True)\n",
        "\n",
        "  #objective of the masked language model is to predict the masked token, the label and the inputs are the same                                        do_lower_case=True)\n",
        "  model = BertForMaskedLM.from_pretrained(pretrained_model,output_attentions=False,\n",
        "                                                          output_hidden_states=True)\n",
        "  model.to(device)\n",
        "  checkpoint = torch.load(FILE,map_location=device)\n",
        "  model.load_state_dict(checkpoint['model_state'])\n",
        "  optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "  optimizer.load_state_dict(checkpoint['optim_state'])\n",
        "  model.to(torch.device('cpu'))\n",
        "  return device , sciBERT_tokenizer , model\n",
        "\n",
        "\n",
        "def convert_single_abstract_to_embedding(in_text, MAX_LEN = 150):\n",
        "    \n",
        "    input_ids = sciBERT_tokenizer.encode(\n",
        "                        in_text, \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = MAX_LEN,                           \n",
        "                   )    \n",
        "    \n",
        "    #print(\"input ids\",input_ids)\n",
        "\n",
        "    results = pad_sequences([input_ids], maxlen=MAX_LEN, dtype=\"long\", \n",
        "                              truncating=\"post\", padding=\"post\")\n",
        "    #print(\"results\",results)\n",
        "    \n",
        "    # Remove the outer list.\n",
        "    input_ids = results[0]\n",
        "    #print(\"input ids\",input_ids)\n",
        "\n",
        "    # Create attention masks    \n",
        "    attention_mask = [int(i>0) for i in input_ids]\n",
        "    #print(\"attention_mask\",attention_mask)\n",
        "    \n",
        "    # Convert to tensors.\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_mask = torch.tensor(attention_mask)\n",
        "    #print(\"input ids\",input_ids)\n",
        "    #print(\"attention_mask\",attention_mask)\n",
        "\n",
        "    # Add an extra dimension for the \"batch\" (even though there is only one \n",
        "    # input in this batch.)\n",
        "    input_ids = input_ids.unsqueeze(0)\n",
        "    attention_mask = attention_mask.unsqueeze(0)\n",
        "\n",
        "    #print(\"input ids\",input_ids)\n",
        "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "    model.eval()\n",
        "\n",
        "    #input_ids = input_ids.to(device)\n",
        "    #attention_mask = attention_mask.to(device)\n",
        "    \n",
        "    # Run the text through BERT, and collect all of the hidden states produced\n",
        "    # from all 12 layers. \n",
        "    with torch.no_grad():        \n",
        "        o  = model(\n",
        "                        input_ids = input_ids, \n",
        "                        token_type_ids = None, \n",
        "                        attention_mask = attention_mask)\n",
        "        \n",
        "        h_s = o[1][1:]\n",
        "\n",
        "    layer_i = 11 # The last BERT layer before the classifier.\n",
        "    batch_i = 0 # Only one input in the batch.\n",
        "    token_i = 0 # The first token, corresponding to [CLS]\n",
        "\n",
        "    #print(h_s[11].shape)\n",
        "    # Extract the embedding.\n",
        "    embedding = h_s[layer_i][batch_i][token_i]\n",
        "\n",
        "    # Move to the CPU and convert to numpy ndarray.\n",
        "    embedding = embedding.detach().cpu().numpy()\n",
        "\n",
        "    return(embedding)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def process_query(query_text):\n",
        "    \"\"\"\n",
        "    # Create a vector for given query and adjust it for cosine similarity search\n",
        "    \"\"\"\n",
        "    query_vect = convert_single_abstract_to_embedding(query_text)\n",
        "    query_vect = np.array(query_vect)\n",
        "    query_vect = query_vect.reshape(1, -1)\n",
        "    return query_vect\n",
        "\n",
        "\n",
        "def get_top_N_articles_cosine(query_text, data, top_N=5):\n",
        "    \"\"\"\n",
        "    Retrieve top_N (5 is default value) articles similar to the query\n",
        "    \"\"\"\n",
        "    query_vect = process_query(query_text)\n",
        "    revevant_cols = [\"title\", \"abstract\", \"cos_sim\"]\n",
        "    \n",
        "    # Run similarity Search\n",
        "    data[\"cos_sim\"] = data[\"embeddings\"].apply(lambda x: cosine_similarity(query_vect, x))\n",
        "    data[\"cos_sim\"] = data[\"cos_sim\"].apply(lambda x: x[0][0])\n",
        "    \n",
        "    \"\"\"\n",
        "    Sort Cosine Similarity Column in Descending Order \n",
        "    Here we start at 1 to remove similarity with itself because it is always 1\n",
        "    \"\"\"\n",
        "    most_similar_articles = data.sort_values(by='cos_sim', ascending=False)[1:top_N+1]\n",
        "    \n",
        "    return most_similar_articles[revevant_cols]\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  data = load_data()\n",
        "  global device , sciBERT_tokenizer , model \n",
        "  device , sciBERT_tokenizer , model  = model_load(\"finalcheckpoint19.pth\")\n",
        "\n",
        "  a_data = pd.read_pickle(\"data_abstract.pkl\")\n",
        "  t_data = pd.read_pickle(\"data_title.pkl\")\n",
        "\n",
        "  t0 = time.time()\n",
        "  output = pd.DataFrame()\n",
        "  query_text_test = [\"HUMAN BRAIN MIMICS\" , \"VLSI neural network\"]\n",
        "  for i in query_text_test:\n",
        "    output = pd.DataFrame()\n",
        "    for j in [a_data,t_data]:\n",
        "      # Get the query text\n",
        "      # Get the similar articles\n",
        "      top_articles = get_top_N_articles_cosine(i, j)\n",
        "      output = pd.concat([top_articles,output], axis=0)\n",
        "    print(\"Results for \\\" \"+i+ \" \\\"query\")\n",
        "    display(output)\n",
        "    print(\"Time taken :\",format_time(time.time() - t0))"
      ]
    }
  ]
}